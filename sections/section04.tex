\section{Основные уравнения в теории поверхностей}

\epigraph{Эти формулы надо запомнить, вот как хотите.\footnotemark}{А.\,А. Гайфуллин}

\footnotetext{Речь шла о формулах \eqref{eq:ChristoffelIdentity} и \eqref{eq:CovariantFormula}.}

\subsection{Деривационные уравнения. Тождества Кристоффеля}

Мы хотим написать для поверхностей что-то похожее на формулы Френе, то есть наша цель --- научиться дифференцировать векторы
\[
	\vec{r}_1 \vcentcolon = \frac{\partial\vec{r}}{\partial u^1},\quad
	\vec{r}_2 \vcentcolon = \frac{\partial\vec{r}}{\partial u^2},
\]
для этого нам будет удобно обозначить
\[
	\vec{r}_{ij} \vcentcolon = \frac{\partial^2\vec{r}}{\partial u^i\partial u^j}.
\]

Векторы $(\vec{r}_1, \vec{r}_2, \vec{n})$ образуют базис в каждой точке поверхности, поэтому каждый вектор $\vec{r}_{ij}$ в нём как-то записывается. Заметим, что коэффициент при $\vec{n}$ мы уже знаем --- это соответствующий элемент матрицы второй квадратичной формы $b_{ij}$. Действительно, ведь по определению $b_{ij} = \langle\vec{r}_{ij}, \vec{n}\rangle$.

\begin{definition}
	Коэффициенты $\Gamma_{ij}^k = \Gamma_{ji}^k$ в разложении
	\begin{equation} \label{eq:DerivativeGauss}
		\vec{r}_{ij} = \Gamma_{ij}^k\vec{r}_k + b_{ij}\vec{n}
	\end{equation}
	называются \textit{символами Кристоффеля}.
\end{definition}

\begin{lemma}[Тождества Кристоффеля]
	Символы Кристоффеля однозначно определяются метрикой на поверхности. Более точно, верна следующая формула:
	\begin{equation} \label{eq:ChristoffelIdentity}
		\Gamma_{ij}^k = \frac{g^{kl}}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}},
	\end{equation}
	где $g^{kl}$ обозначают элементы матрицы $\G^{-1}$.
\end{lemma}

\begin{proof}
	Напишем
	\begin{equation} \label{eq:FirstFormula}
		\langle\vec{r}_{ij}, \vec{r}_l\rangle = \Gamma_{ij}^s\langle\vec{r}_s, \vec{r}_l\rangle = \Gamma_{ij}^sg_{sl}
	\end{equation}
	и
	\[\begin{tikzcd}
		{\ds\frac{\partial g_{il}}{\partial u^j}} & {\ds\frac{\partial}{\partial u^j}\langle\vec{r}_i, \vec{r}_l\rangle} & {\langle\vec{r}_{ij}, \vec{r}_l\rangle + \langle\vec{r}_i, \vec{r}_{jl}\rangle.}
		\arrow[equals, from=1-1, to=1-2]
		\arrow[equals, from=1-2, to=1-3]
	\end{tikzcd}\]
	Последнюю формулу напишем три раза, сдвигая координаты:
	\begin{gather} \label{eq:SecondFormula}
		\frac{\partial g_{il}}{\partial u^j} = \langle\vec{r}_{ij}, \vec{r}_l\rangle \phantom{{} + \langle\vec{r}_j, \vec{r}_{il}\rangle} + \langle\vec{r}_i, \vec{r}_{jl}\rangle\nonumber,\\
		\frac{\partial g_{jl}}{\partial u^i} = \langle\vec{r}_{ij}, \vec{r}_l\rangle + \langle\vec{r}_j, \vec{r}_{il}\rangle \phantom{{} + \langle\vec{r}_i, \vec{r}_{jl}\rangle}\nonumber,\\
		\frac{\partial g_{ij}}{\partial u^l} = \phantom{\langle\vec{r}_{ij}, \vec{r}_l\rangle + {}} \langle\vec{r}_{il}, \vec{r}_j\rangle + \langle\vec{r}_i, \vec{r}_{jl}\rangle.
	\end{gather}
	Сложим первые две строки из них и вычтем третью, получим
	\begin{gather*}
		\langle\vec{r}_{ij}, \vec{r}_l\rangle = \frac{1}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}}.
	\end{gather*}
	Теперь подставляем \eqref{eq:FirstFormula}:
	\[
		g_{ls}\Gamma_{ij}^s = \frac{1}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}}.
	\]
	Домножаем обе части на $g^{kl}$ и суммируем по $k$. Слева получим $g^{kl}g_{ls}\Gamma^s_{ij} = \delta^k_s\Gamma^s_{ij} = \Gamma^k_{ij}$:
	\[
		\Gamma_{ij}^k = \frac{g^{kl}}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}}.
	\]
\end{proof}

Отметим, что попутно мы доказали ещё один набор важных формул. Можно напрямую подставить в \eqref{eq:SecondFormula} формулы вида \eqref{eq:FirstFormula}, получим следующее.

\begin{lemma}
	Выполнены следующие тождества:
	\begin{equation} \label{eq:AlmostCristoffelIdentity}
		\frac{\partial g_{ij}}{\partial u^k} = g_{js}\Gamma^s_{ik} + g_{is}\Gamma^s_{jk}.
	\end{equation}
\end{lemma}

Следует отметить, что символы Кристоффеля не задают никакого тензора в касательном пространстве к поверхности.

\begin{problem} \label{problem:ChristoffelNotTensor}
	Вывести формулы преобразования символов Кристоффеля при переходе к новым координатам. (И убедиться, что они не совпадают с тензорными.)
\end{problem}

\begin{solution}
	Для удобства будем обозначать частную производную по $u^i$ через $\partial_i$ (аналогично для других индексов). Мы знаем тождества Кристоффеля:
	\[
		\widetilde{\Gamma}_{ij}^k = \frac{g^{kl}}{2}(\partial_ig_{jl} + \partial_jg_{il} - \partial_lg_{ij}).
	\]
	Метрика преобразуется, как тензор ранга $2$:
	\[
		\widetilde{g}_{ij} = \frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}g_{pq},\quad \widetilde{g}^{kl} = \frac{\partial \widetilde{u}^k}{\partial u^m}\frac{\partial \widetilde{u}^l}{\partial u^n}g^{mn}.
	\]
	Вычислим $\partial_ig_{jl}$ в новых координатах:
	\[
		\frac{\partial}{\partial \widetilde{u}^i}\widetilde{g}_{jl} = \frac{\partial}{\partial \widetilde{u}^i}\br{\frac{\partial u^q}{\partial \widetilde{u}^j}\frac{\partial u^r}{\partial \widetilde{u}^l}g_{qr}} = \big(\partial_pg_{qr}\big)\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}\frac{\partial u^r}{\partial \widetilde{u}^l} + g_{qr}\br{\frac{\partial^2u^q}{\partial\widetilde{u}^i\partial\widetilde{u}^j}\frac{\partial u^r}{\partial\widetilde{u}^l} + \frac{\partial^2u^r}{\partial\widetilde{u}^i\partial\widetilde{u}^l}\frac{\partial u^q}{\partial\widetilde{u}^j}}.
	\]
	Подставляем в тождества Кристоффеля для $\widetilde{\Gamma}_{ij}^k$:
	\begin{gather*}
		\widetilde{\Gamma}_{ij}^k = \frac{\widetilde{g}^{kl}}{2}\left(
		\big(\partial_pg_{qr}\big)\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}\frac{\partial u^r}{\partial \widetilde{u}^l} + g_{qr}\br{\frac{\partial^2u^q}{\partial\widetilde{u}^i\partial\widetilde{u}^j}\frac{\partial u^r}{\partial\widetilde{u}^l} + \frac{\partial^2u^r}{\partial\widetilde{u}^i\partial\widetilde{u}^l}\frac{\partial u^q}{\partial\widetilde{u}^j}}\right. + {}\\
		{} + \big(\partial_qg_{pr}\big)\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}\frac{\partial u^r}{\partial \widetilde{u}^l} + g_{qr}\br{\frac{\partial^2u^q}{\partial\widetilde{u}^j\partial\widetilde{u}^i}\frac{\partial u^r}{\partial\widetilde{u}^l} + \frac{\partial^2u^r}{\partial\widetilde{u}^j\partial\widetilde{u}^l}\frac{\partial u^q}{\partial\widetilde{u}^i}} - {}\\
		{} - \left.\big(\partial_rg_{pq}\big)\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}\frac{\partial u^r}{\partial \widetilde{u}^l} - g_{qr}\br{\frac{\partial^2u^q}{\partial\widetilde{u}^l\partial\widetilde{u}^i}\frac{\partial u^r}{\partial\widetilde{u}^j} + \frac{\partial^2u^r}{\partial\widetilde{u}^l\partial\widetilde{u}^j}\frac{\partial u^q}{\partial\widetilde{u}^i}}\right).
	\end{gather*}
	В последней формуле отдельно вынесим первые слагаемые в каждой большой скобке:
	\begin{multline*}
		\frac{\widetilde{g}^{kl}}{2}\br{\big(\partial_pg_{qr}\big) + \big(\partial_qg_{pr}\big) - \big(\partial_rg_{pq}\big)}\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}\frac{\partial u^r}{\partial \widetilde{u}^l} =\\ = \frac{g^{mn}}{2}\frac{\partial\widetilde{u}^k}{\partial u^m}\frac{\partial\widetilde{u}^l}{\partial u^n}\br{\big(\partial_pg_{qr}\big) + \big(\partial_qg_{pr}\big) - \big(\partial_rg_{pq}\big)}\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}\frac{\partial u^r}{\partial \widetilde{u}^l} =\\ = \frac{g^{mn}}{2}\br{\big(\partial_pg_{qr}\big) + \big(\partial_qg_{pr}\big) - \big(\partial_rg_{pq}\big)}\frac{\partial \widetilde{u}^k}{\partial u^m}\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}\delta_n^r =\\ = {\underbrace{\frac{g^{mr}}{2}\br{\big(\partial_pg_{qr}\big) + \big(\partial_qg_{pr}\big) - \big(\partial_rg_{pq}\big)}}_{\ds\Gamma_{pq}^m}}\frac{\partial \widetilde{u}^k}{\partial u^m}\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j}.
	\end{multline*}
	Эта часть соответствует тензорному закону. Посчитаем остаток:
	\begin{multline*}
		\widetilde{g}^{kl}g_{qr}\br{\frac{\partial^2u^q}{\partial\widetilde{u}^i\partial\widetilde{u}^j}\frac{\partial u^r}{\partial\widetilde{u}^l}} = g^{mn}g_{qr}\frac{\partial\widetilde{u}^k}{\partial u^m}\frac{\partial\widetilde{u}^l}{\partial u^n}\br{\frac{\partial^2u^q}{\partial\widetilde{u}^i\partial\widetilde{u}^j}\frac{\partial u^r}{\partial\widetilde{u}^l}} = \\ = \left\{\frac{\partial \widetilde{u}^l}{\partial u^n}\frac{\partial u^r}{\partial \widetilde{u}^l} = \delta^r_n\right\} = {\underbrace{g^{mr}g_{rq}}_{\delta^m_q}}\frac{\partial\widetilde{u}^k}{\partial u^m}\frac{\partial^2u^m}{\partial\widetilde{u}^i\partial\widetilde{u}^j} = \frac{\partial\widetilde{u}^k}{\partial u^m}\frac{\partial^2u^m}{\partial\widetilde{u}^i\partial\widetilde{u}^j}.
	\end{multline*}

	Таким образом, получаем формулу преобразования символов Кристоффеля при переходе к новым координатам:
	\[
		\widetilde{\Gamma}_{ij}^k = \Gamma_{pq}^m\frac{\partial \widetilde{u}^k}{\partial u^m}\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j} + \frac{\partial\widetilde{u}^k}{\partial u^m}\frac{\partial^2u^m}{\partial\widetilde{u}^i\partial\widetilde{u}^j}.
	\]

	Из полученных формул видно, что символы Кристоффеля преобразуются, как тензоры, тогда и только тогда, когда замена координат $(u^1, u^2) \to (\widetilde{u}^1, \widetilde{u}^2)$ линейна.
\end{solution}

\noindent
Уравнения \eqref{eq:DerivativeGauss} с подстановкой \eqref{eq:ChristoffelIdentity} называются \textit{деривационными уравнениями Гаусса}.

Теперь хотим дифференцировать вектор $\vec{n}$. Обозначим
\[
	\vec{n}_1 \vcentcolon = \frac{\partial \vec{n}}{\partial u^1}\quad\text{и}\quad\vec{n}_2 \vcentcolon = \frac{\partial \vec{n}}{\partial u^2}.
\]

Поскольку вектор $\vec{n}$ имеет постоянную длину, оба этих вектора ортогональны $\vec{n}$, а значит, выражаются через базисные векторы $\vec{r}_1$, $\vec{r}_2$ касательного пространства в соответствующей точке. Пока напишем формально:
\begin{equation} \label{eq:DerivativeWeingarten}
	\vec{n}_i = c^j_i\vec{r}_j,
\end{equation}
позже мы придадим коэффициентам $c^j_i$ какой-то смысл.

\begin{lemma}
	Имеет место равенство
	\begin{equation} \label{eq:WeingartenIdentity}
		c^j_i = -g^{jk}b_{ki},
	\end{equation}
	где $g^{jk}$ обозначают элементы матрицы $\G^{-1}$.
\end{lemma}

\begin{proof}
	Векторы $\vec{n}$ и $\vec{r}_k$ ортогональны (по построению), поэтому
	\[
		\langle\vec{n}_i, \vec{r}_k\rangle = -\langle\vec{n}, \vec{r}_{ik}\rangle = -b_{ik}.
	\]
	Подставляя выражение для $\vec{n}_i$, получаем
	\[\begin{tikzcd}
		{c^j_i\langle\vec{r}_j, \vec{r}_k\rangle} & {c^j_ig_{jk}} & {-b_{ik}}
		\arrow[equals, from=1-1, to=1-2]
		\arrow[equals, from=1-2, to=1-3]
	\end{tikzcd}\]
	Переписываем в матричном виде (с учётом $b_{ik} = b_{ki}$):
	\[
		\G C = -\B,\,\text{где }C = (c^j_i).
	\]
	Из него можно выразить матрицу $C$ как $C = -\G^{-1}\B$, или, в обозначениях Эйнштейна,
	\[
		c^j_i = -g^{jk}b_{ki}.
	\]
\end{proof}

Уравнения \eqref{eq:DerivativeWeingarten} с подстановкой \eqref{eq:WeingartenIdentity} называются \textit{деривационными уравнениями Вайнгартена}. Вместе, уравнения
\begin{equation} \label{eq:DerivativeEquations}
	\begin{cases}
		\vec{r}_{ij} = \Gamma_{ij}^k\vec{r}_k + b_{ij}\vec{n},\\
		\vec{n}_i = c^j_i\vec{r}_j
	\end{cases}
\end{equation}
называются \textit{деривационными уравнениями Гаусса "---Вайнгартена}. Заметим, что все коэффициенты этих уравнений выражаются через первую и вторую квадратичные формы поверхности. Так что, разрешив эти уравнения относительно $\vec{r}$, по первой и второй квадратичной форме мы восстановим поверхность. Так же мы раньше восстанавливали пространственные кривые по кривизне и кручению. Отметим, однако, что если кривую можно было восстановить про произвольным гладким функциям кривизны и кручения, то теперь для деривационных уравнений имеется нетривиальное условие совместности. Мы вернёмся к этому позже в следующем разделе.

Теперь обсудим смысл коэффициентов $c^j_i$. Разумеется, они зависят от параметризации, но матрица $C$ преобразуется как матрица линейного оператора в касательном пространстве к поверхности, так как $C = -\G^{-1}\B$.

\begin{definition}
	\textit{Сферическим отображением} гладкой поверхности $\M$ называется отображение $\vec{\nu}\colon \M \to S^2$, которое каждой точке $\vec{x}$ поверхности ставит в соответствие единичный вектор нормали $\vec{n}$ к соответствующей касательной плоскости $\T_{\vec{x}}\M$.
\end{definition}

Это определение, строго говоря, задаёт отображение $\vec{\nu}$ лишь с точностью до знака. Знак $\vec{n}$ выбирается таким, чтобы тройка векторов $(\vec{r}_1, \vec{r}_2, \vec{n})$ была положительно ориентированной.

\begin{proposition}
	Для любой точки $\vec{x}$ поверхности $\M$ касательные пространства $\T_{\vec{x}}\M$ и $\T_{\vec{\nu}(\vec{x})}S^2$ совпадают.
\end{proposition}

\begin{proof}
	Вектор $\vec{\xi}$ лежит в касательном пространстве $\T_{\vec{x}}\M$ тогда и только тогда, когда $\vec{\xi} \perp \vec{n}$. При этом же условии он лежит в касательном пространстве $\T_{\vec{\nu}(\vec{x})}S^2$.
\end{proof}

Последнее предложение означает, что дифференциал $d\vec{\nu}|_{\vec{x}}$ сферического отображения можно понимать как линейный оператор на касательном пространстве. Сопоставляя определение дифференциала и деривационные формулы Вайнгартена $\vec{n}_i = -g^{jk}b_{ki}\vec{r}_j$, мы немедленно получаем следующее утверждение.

\begin{proposition}
	Оператор $d\vec{\nu}$ имеет в базисе $\vec{r}_1$, $\vec{r}_2$ матрицу $C = (c^j_i)$, элементы которой определены формулами \eqref{eq:WeingartenIdentity}.
\end{proposition}

\begin{definition}
	Оператор, заданный в касательном пространстве матрицей $C$, называется \textit{оператором Вайнгартена}.
\end{definition}

\begin{theorem} \label{theorem:Weingarten}
	Оператор Вайнгартена самосопряжён относительно скалярного произведения, заданного в $\T_{\vec{x}}\M$ первой квадратичной формой. Векторы главных направлений $\vec{\xi}_1$ и $\vec{\xi}_2$ являются для него собственными, а соответствующие им собственные значения суть главные кривизны, взятые с обратным знаком: $-\lambda_1$, $-\lambda_2$. Кроме того, имеют место равенства
	\[
		\det\br{d\nu|_{\vec{x}}} = \frac{\det\B}{\det\G} = K.
	\]
\end{theorem}

\noindent
Эта теорема доказывается прямой проверкой всех определений.

\subsection{Совместность деривационных уравнений и теорема Бонне}

Запишем деривационные уравнения \eqref{eq:DerivativeEquations} в матричном виде:
\[
	\frac{\partial}{\partial u^i}
	\begin{pmatrix}
		\vec{r}_1 & \vec{r}_2 & \vec{n}
	\end{pmatrix} =
	\begin{pmatrix}
		\vec{r}_1 & \vec{r}_2 & \vec{n}
	\end{pmatrix}A_i,
\]
где
\[
	A_i =
	\begin{pmatrix}
		\Gamma_{i1}^1 & \Gamma_{i1}^2 & -b_{ik}g^{k1}\\
		\Gamma_{i2}^1 & \Gamma_{i2}^2 & -b_{ik}g^{k2}\\
		b_{i1} & b_{i2} & 0
	\end{pmatrix}.
\]

Если рассматривать эти уравнения как пару дифференциальных уравнений на матрицу $X = (\vec{r}_1, \vec{r}_2, \vec{n})$, то условие совместности \eqref{eq:Darboux} из теоремы Дарбу для них принимает вид
\[
	\frac{\partial}{\partial u^1}A_2 + A_1A_2 = \frac{\partial}{\partial u^2}A_1 + A_2A_1,
\]
что можно переписать как
\begin{equation} \label{eq:Jointness}
	\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} = [A_1, A_2],
\end{equation}
где $[A_1, A_2] = A_1A_2 - A_2A_1$ --- коммутатор матриц.

В формулировке следующей теоремы поверхность понимается в более широком смысле, чем в наших определениях. А именно, поверхности разрешается иметь самопересечения.

\begin{theorem}[Бонне]
	Пусть $g_{ij}(u^1, u^2)$, $b_{ij}(u^1, u^2)$, где $i, j = 1, 2$, --- набор гладкий функций в замкнутой односвязной области $\Omega \subset \R^2$, удовлетворяющие условиям: матрицы $G = (g_{ij})$ и $B = (b_{ij})$ симметричны для всех точек $(u^1, u^2) \in \Omega$, причём матрица $G$ положительно определена. Тогда
	\begin{enumerate}[nolistsep, label=(\arabic*)]
		\item в $\R^3$ существует поверхность $\M$ с регулярной параметризацией $\Omega \to \M$, для которой первая и вторая квадратичные формы равны
			\[
				\I = g_{ij}du^idu^j,\quad\II = b_{ij}du^idu^j
			\]
			тогда и только тогда, когда функции $g_{ij}$, $b_{ij}$ ($i, j = 1, 2$) удовлетворяют условиям совместности \eqref{eq:Jointness};
		\item если поверхность с такими квадратичными формами существует, то она единственна с точностью до движения всего пространства $\R^3$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Чтобы не углубляться в технические детали, проведём доказательство в том случае, когда область $\Omega$ является квадратом $[0; 1] \times [0; 1]$.

	Покажем необходимость условий \eqref{eq:Jointness}. Пусть данные коэффициенты $(g_{ij})$ и $(b_{ij})$ соответствуют некоторой поверхности в $\R^3$ с параметризацией $\vec{r}(u^1, u^2)$. Тогда матрица $X =
	\begin{pmatrix}
		\vec{r}_1 & \vec{r}_2 & \vec{n}
	\end{pmatrix}$ удовлетворяет паре уравнений
	\[
		\frac{\partial}{\partial u^1}X = XA_1,\quad 
		\frac{\partial}{\partial u^2}X = XA_2,
	\]
	то есть, казабось бы, мы умеем решать систему только при одном начальном условии $X|_{(0, 0)}$, а хотим при всех (см. условие теоремы Дарбу \ref{theorem:Darboux}). Но заметим, что уравнения \eqref{eq:Jointness} линейные, а потом замена $X \mapsto CX$ (где $C$ --- любая матрица) переводит одно системы решение в другое. Так что возможность решить систему при каком-то одном начальном условии даёт нам возможность решить её при любых начальных условиях\footnotemark.
	
	\footnotetext{Отметим, что это общая специфика любых \underline{линейных} систем дифференциальных уравнений.}

	Теперь обсудим единственность восстановления с точностью до движений $\R^3$. Векторы $\vec{r}_1$, $\vec{r}_2$ и $\vec{n}$ удовлетворяют системе обыкновенных дифференциальных уравнений
	\[
		\frac{\partial}{\partial u^1}\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} A_1,
	\]
	которое полностью определяет их в точках вида $(u^1, 0)$ для всех $u^1$ при известных начальных значениях $\vec{r}_1|_{(0, 0)}$, $\vec{r}_2|_{(0, 0)}$, $\vec{n}|_{(0, 0)}$. Далее, из уравнения
	\[
		\frac{\partial}{\partial u^2}\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} A_2
	\]
	значения $\vec{r}_1$, $\vec{r}_2$ и $\vec{n}$ находятся во всех точках $(u^1, u^2) \in \Omega$. Аналогичным образом, параметризация $\vec{r}(u^1, u^2)$ находится однозначно при известных $\vec{r}_1$ и $\vec{r}_2$, если известно начальное условие $\vec{r}|_{(0, 0)}$.

	Таким образом, вся неоднозначность восстановления поверхности сводится к выбору начальных значений $\vec{r}|_{(0, 0)}$, $\vec{r}_1|_{(0, 0)}$, $\vec{r}_2|_{(0, 0)}$ и $\vec{n}|_{(0, 0)}$. При этом нам жёстко задана матрица Грама последних трёх векторов (а первый есть просто радиус-вектор точки, к которой приложен репер). Поэтому единственная свобода выбора начальных условий --- это движения всего пространства $\R^3$.

	Перейдём к сложной части --- достаточности. Согласно теореме Дарбу \ref{theorem:Darboux} условия совместности \eqref{eq:Jointness} дают возможность найти векторы $\vec{v}_1$, $\vec{v}_2$ и $\vec{n}$, удовлетворяющие уравнениям
	\begin{equation} \label{eq:DerivativeMatrix}
		\frac{\partial}{\partial u^1}
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}A_1,\quad
		\frac{\partial}{\partial u^2}
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}A_2
	\end{equation}
	в некоторой окрестности точки $(u^1, u^2) = (0, 0)$ при данном начальном условии. Так что вопрос здесь только в том, чтобы решить эти уравнения на всём квадрате $\Omega$, а не только в малой окрестности начала координат. В данном случае решение распространяется на всю область, так как рассматриваемые уравнения линейны, а линейные уравнения решаются <<сколь угодно далеко>>. Здесь также важно, что процедура восстановления векторов $\vec{v}_1$, $\vec{v}_2$ и $\vec{n}$, описанная на предыдущем шаге (где эти же векторы обозначались через, соответственно, $\vec{r}_1$, $\vec{r}_2$ и $\vec{n}$), в точности повторяет процедуру построения решения в доказательстве теоремы Дарбу \ref{theorem:Darboux}. Как там было показано, при выполнении условий совместности, такая процедура приводит к решению обоих уравнений системы.

	Далее, собственно для восстановления поверхности, нужно при уже известных векторах $\vec{v}_1$, $\vec{v}_2$ решить уравнения
	\begin{equation} \label{eq:SurfaceRecuperation}
		\frac{\partial}{\partial u^1}\vec{r} = \vec{v}_1,\quad
		\frac{\partial}{\partial u^2}\vec{r} = \vec{v}_2.
	\end{equation}
	Условие совместности для этой системы имеет вид
	\[
		\frac{\partial}{\partial u^2}\vec{v}_1 = \frac{\partial}{\partial u^1}\vec{v}_2
	\]
	(см. пример \ref{example:SimpleDiffJointness}). Оно выполнено, так как верны формулы
	\[
		\frac{\partial\vec{v}_i}{\partial u^j} = \Gamma_{ij}^k\vec{v}_k + b_{ij}\vec{n}.
	\]
	(Они, в свою очередь, верны просто в силу уравнений \eqref{eq:DerivativeMatrix}.) Действительно, ведь правые части этих формул симметричны по $i$ и $j$, а значит, и левые тоже. Таким образом, локальных препятствий к решению системы \eqref{eq:SurfaceRecuperation} нет, а существование решения на всём квадрате снова следует из вида уравнений, здесь правая часть не зависит от $\vec{r}$, и они решаются простым интегрированием.

	Итак, мы построили решения системы 
	\[
		\begin{cases}
			\begin{aligned}
				& \ds\frac{\partial}{\partial u^i}
				\begin{pmatrix}
					\vec{v}_1 & \vec{v}_2 & \vec{n}
				\end{pmatrix} =
				\begin{pmatrix}
					\vec{v}_1 & \vec{v}_2 & \vec{n}
				\end{pmatrix}A_i,\\
				& \ds\frac{\partial \vec{r}}{\partial u^j} = \vec{v}_j
			\end{aligned}
		\end{cases}
	\]
	с начальными условиями на $\vec{r}|_{(0, 0)}$, $\vec{r}_1|_{(0, 0)}$, $\vec{r}_2|_{(0, 0)}$ и $\vec{n}|_{(0, 0)}$. Теперь нас беспокоит следующий вопрос --- а действительно ли данные нам $g_{ij}$ и $b_{ij}$ ($i, j = 1, 2$) являются коэффициентами, соответственно, первой и второй квадратичной формы построенной нами поверхности?

	Рассмотрим матрицу $\widetilde{G}$ первой квадратичной формы нашей поверхности, то есть матрицу Грама векторов $(\vec{r}_1, \vec{r}_2, \vec{n})$:
	\[
		\widetilde{G} \vcentcolon =
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}^t
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}.
	\]
	В силу уравнений \eqref{eq:DerivativeMatrix} напишем:
	\[
		\frac{\partial}{\partial u^i}\widetilde{G} = 
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}^t_{u^i}
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix} + 
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}^t
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}_{u^i} = A_i^t\widetilde{G} + \widetilde{G}A_i.
	\]
	А теперь рассмотрим матрицу
	\[
		\widehat{G} \vcentcolon =
		\begin{pmatrix}
			g_{11} & g_{12} & 0\\
			g_{12} & g_{22} & 0\\
			0 & 0 & 1
		\end{pmatrix}.
	\]
	Оказывается, для неё выполнены те же формулы.

	\begin{lemma} \label{lemma:Gui}
		Выполнено
		\[
			A_i^t\widehat{G} + \widehat{G}A_i = \frac{\partial}{\partial u^i}\widehat{G}.
		\]
	\end{lemma}

	\begin{proof}
		Отметим, что матрица в левой части точно нулевая всюду, кроме главного минора $2 \times 2$. Действительно, для правой нижней клетки это очевидно, а для остальных легко проверить. Проверим, например, для нижней центральной клетки:
		\[
			\begin{pmatrix}
				-b_{ik}g^{k1} & -b_{ik}g^{k2} & 0
			\end{pmatrix}
			\begin{pmatrix}
				g_{12}\\
				g_{22}\\
				0
			\end{pmatrix} +
			\begin{pmatrix}
				0 & 0 & 1
			\end{pmatrix}
			\begin{pmatrix}
				\Gamma_{11}^2\\
				\Gamma_{12}^2\\
				b_{i2}
			\end{pmatrix} = -b_{ik}g^{ks}g_{s2} + b_{i2} = -b_{i2} + b_{i2} = 0.
		\]
		
		Таким образом, вне главного минора $2 \times 2$ матрицы в левой и правой частях данного равенства обе нулевые. А внутри него у матрицы в левой части мы получаем правые части формул \eqref{eq:AlmostCristoffelIdentity}, что также совпадает с тем, что мы хотели получить.
	\end{proof}

	Итак, мы поняли, что матрицы $\widehat{G}$ и $\widetilde{G}$ удовлетворяют одним и тем же дифференциальным уравнениям. Мы также знаем, что в начальный момент эти матрицы совпадают: $\widehat{G}|_{(0, 0)} \hm= \widetilde{G}|_{(0, 0)}$. В силу дифференциальных уравнений, наши матрицы однозначно восстанавливаются по начальному условию, поэтому на самом деле они совпадают всюду.

	Таким образом, $\langle\vec{v}_i, \vec{v}_j\rangle = g_{ij}$ и $\langle\vec{v}_k, \vec{n}\rangle = 0$, поэтому наши $g_{ij}$ действительно являются элементами матрицы первой квадратичной формы нашей поверхности, а вектор $\vec{n}$ --- вектором нормали. Теперь
	\[
		\left\langle\frac{\partial\vec{v}_i}{\partial u^j}, \vec{n}\right\rangle = \langle\Gamma_{ij}^k\vec{v_k} + b_{ij}\vec{n}, \vec{n}\rangle = b_{ij},
	\]
	так как $\vec{v}_k \perp \vec{n}$.
\end{proof}

\subsection{Уравнения Гаусса "---Кодацци}

На первый взгляд, система \eqref{eq:Jointness} содержит девять уравнений. Распишем их подробно, чтобы выяснить их истинное число и конкретный вид. Обозначим через $\widehat{G}$ матрицу Грама векторов $(\vec{r}_1, \vec{r}_2, \vec{n})$:
\[
	\widehat{G} \vcentcolon =
	\begin{pmatrix}
		g_{11} & g_{12} & 0\\
		g_{12} & g_{22} & 0\\
		0 & 0 & 1
	\end{pmatrix}.
\]

Ясно, что матрица $\widehat{G}$ невырожденна (её определитель равен определителю матрицы $\G$ первой квадратичной формы), а потому, домножив матрицу в левой части \eqref{eq:Jointness} на $\widehat{G}$, получим равносильную систему уравнений.

\begin{lemma}
	Матрица $\ds\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}$ кососимметрична.
\end{lemma}

\begin{proof}
	Обозначим эту матрицу через $S$. Применяя лемму \ref{lemma:Gui}, напишем
	\begin{multline*}
		S = \frac{\partial(\widehat{G}A_1)}{\partial u^2} - \frac{\partial \widehat{G}}{\partial u^2}A_1 - \frac{\partial(\widehat{G}A_2)}{\partial u^1} + \frac{\partial \widehat{G}}{\partial u^1}A_2 - \widehat{G}A_1A_2 + \widehat{G}A_2A_1 =\\ = \frac{\partial(\widehat{G}A_1)}{\partial u^2} - A_2^t\widehat{G}A_1 - \cancel{\widehat{G}A_2A_1} - \frac{\partial(\widehat{G}A_2)}{\partial u^1} + A_1^t\widehat{G}A_2 + \bcancel{\widehat{G}A_1A_2} - \bcancel{\widehat{G}A_1A_2} + \cancel{\widehat{G}A_2A_1} =\\ = \frac{\partial(\widehat{G}A_1)}{\partial u^2} - \frac{\partial(\widehat{G}A_2)}{\partial u^1} + {\underbrace{A_1^t\widehat{G}A_2 - A_2^t\widehat{G}A_1}_{\text{кососимметрична}}}.
	\end{multline*}
	Далее пишем
	\[
		S + S^t = \frac{\partial(\widehat{G}A_1 + A_1^t\widehat{G})}{\partial u^2} - \frac{\partial(\widehat{G}A_2 + A_2^t\widehat{G})}{\partial u^1} = \cancel{\frac{\partial^2\widehat{G}}{\partial u^1u^2}} - \cancel{\frac{\partial^2\widehat{G}}{\partial u^1u^2}} = 0.
	\]
	Таким образом, матрица $S$ кососимметрична.
\end{proof}

Итак, мы свели систему уравнений \eqref{eq:Jointness} на матрицу $3 \times 3$ к равносильной системе с кососимметричной матрицей. А у такой системы может быть не более трёх независимых уравнений. Будем изучать их по отдельности.

\begin{definition}
	Уравнение
	\[
		\br{\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}}_{12} = 0
	\]
	называется \textit{уравнением Гаусса}.
\end{definition}

\noindent%
Подставив матрицы $\widehat{G}$ и $A_i$, получаем развёрнутый вид уравнения Гаусса:
\begin{equation} \label{eq:Gauss}
	g_{1k}\br{\frac{\partial\Gamma^k_{22}}{\partial u^1} - \frac{\partial\Gamma_{21}^k}{\partial u^2} + \Gamma_{k1}^s\Gamma^k_{22} - \Gamma_{s2}^k\Gamma_{21}^s} - b_{12}b_{22} + b_{12}^2 = 0.
\end{equation}

Замечательно в этом уравнении то, что из него можно выразить определитель матрицы второй квадратичной формы через символы Кристоффеля, которые, в свою очередь, определяются только метрикой. Отсюда можем сделать следующие выводы.

\begin{theorem}[Гаусс]
	Гауссова кривизна однозначно определяется метрикой. Более точно, выполнена следующая формула:
	\[
		K = \frac{1}{g_{11}g_{22} - g_{12}^2}g_{1k}\br{\frac{\partial\Gamma^k_{22}}{\partial u^1} - \frac{\partial\Gamma_{21}^k}{\partial u^2} + \Gamma_{k1}^s\Gamma^k_{22} - \Gamma_{s2}^k\Gamma_{21}^s}.
	\]
\end{theorem}

\begin{corollary}
	Если $\vec{\varphi}\colon \M \to \mathcal{N}$ --- изометрия поверхностей, то для всех точек $\vec{x} \in \M$ гауссова кривизна поверхности $\mathcal{N}$ в точке $\vec{\varphi}(\vec{x})$ совпадает с гауссовой кривизной поверхности $\M$ в точке $\vec{x}$.
\end{corollary}

Обратное, вообще говоря, неверно --- существуют не локально изометричные поверхности с одинаковыми гауссовыми кривизнами. % TODO: привести пример!

\begin{problem}
	Две поверхности с равными \underline{постоянными} гауссовыми кривизнами локально изометричны.
\end{problem}

Вернёмся к уравнениям совместности. Мы рассмотрели одно уравнение из трёх независимых, осталось ещё два.

\begin{definition}
	Уравнения
	\[
		\br{\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}}_{31} = 0,\quad
		\br{\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}}_{32} = 0
	\]
	называются \textit{уравнениями Кодацци}.
\end{definition}

\noindent
При выполнении нужных подстановок уравнения Кодацци обретают вид
\begin{equation} \label{eq:Codazzi}
	\frac{\partial b_{12}}{\partial u^1} - \frac{\partial b_{11}}{\partial u^2} + b_{s1}\Gamma_{12}^s - b_{s2}\Gamma_{11}^s = 0,\quad
	\frac{\partial b_{22}}{\partial u^1} - \frac{\partial b_{21}}{\partial u^2} + b_{s1}\Gamma_{22}^s - b_{s2}\Gamma_{21}^s = 0.
\end{equation}

Вместе уравнения \eqref{eq:Gauss} и \eqref{eq:Codazzi} называются \textit{уравнениями Гаусса "---Кодацци} и выражают совместность деривационных уравнений Гаусса "---Вайнгартена.

\subsection{Векторные поля, скобка Ли}

\begin{definition}
	\textit{Векторным полем} на поверхности $\M$ называется отображение, которое каждой точке $\vec{x} \in \M$ ставит в соответствие вектор $\vec{v}(\vec{x})$ из касательной плоскости $\T_{\vec{x}}\M$. Векторное поле $\vec{v}$ называется \textit{гладким}, если в локальной параметризации коэффициенты $V^1$, $V^2$ разложения
	$\vec{v} = V^i\vec{r}_i$ вектора $\vec{v}$ по базису $\vec{r}_1$, $\vec{r}_2$ являются гладкими функциями.
\end{definition}

С каждой локальной системой координат связаны два базисных векторных поля, определённых в соответствующей области на поверхности --- это $\vec{r}_1$ и $\vec{r}_2$. Их координаты по отношению к этой локальной системе постоянны: $(1, 0)$ и $(0, 1)$ соответственно. Зададим следующий вопрос: когда данная пара векторных полей $\vec{v}$, $\vec{w}$ может быть парой базисных векторных полей для некоторой локальной системы координат?

Разумеется, для начала нужно потребовать, чтобы $\vec{v}$ и $\vec{w}$ были линейно независимы в каждой точке. Пусть это так в некоторой точке $\vec{x}_0$. Тогда они линейно независимы и в некоторой окрестности $U$ точки $\vec{x}_0$. Пусть $u^1$, $u^2$ --- некоторая локальная система координат в этой окрестности. Мы хотим выяснить, существует ли другая система координат $\widetilde{u}^1$, $\widetilde{u}^2$, для которой всюду в $U$ будет выполнено
\begin{equation} \label{eq:BasisVectorField}
	\frac{\partial}{\partial\widetilde{u}^1}\vec{r} = \vec{v},\quad \frac{\partial}{\partial\widetilde{u}^2}\vec{r} = \vec{w}.
\end{equation}
Найти такую систему координат $\widetilde{u}^1$, $\widetilde{u}^2$ означает найти функции перехода от неё к $u^1$, $u^2$ (или наоборот, что эквивалентно). Равенства \eqref{eq:BasisVectorField} равносильны следующим:
\[
	\frac{\partial u^i}{\partial \widetilde{u}^1}\vec{r}_i = V^i\vec{r}_i,\quad
	\frac{\partial u^i}{\partial \widetilde{u}^2}\vec{r}_i = W^i\vec{r}_i,
\]
то есть следующей системе из двух дифференциальных уравнений:
\[
	\begin{cases}
		\begin{aligned}
			& \frac{\partial u^i}{\partial\widetilde{u}^1}\vec{r}_i = V^i(u^1, u^2),\\
			& \frac{\partial u^i}{\partial\widetilde{u}^2}\vec{r}_i = W^i(u^1, u^2).
		\end{aligned}
	\end{cases}
\]
Выписываем для неё условие совместности \eqref{eq:Darboux}:
\[
	\frac{\partial V^i}{\partial u^j}W^j = \frac{\partial W^i}{\partial u^j}V^j.
\]

\begin{definition}
	Для двух векторных полей $\vec{v}$, $\vec{w}$ их \textit{коммутатором} (\textit{скобкой Ли}) называется векторное поле
	\[
		[\vec{v}, \vec{w}] = \br{V^j\frac{\partial W^i}{\partial u^j} - W^j\frac{\partial V^i}{\partial u^j}}\vec{r}_i.
	\]
	Если $[\vec{v}, \vec{w}] \equiv \vec{0}$, то говорят, что поля $\vec{v}$ и $\vec{w}$ \textit{коммутируют}.
\end{definition}

% TODO: написать про геометрический смысл скобки Ли

\begin{proposition}
	Определение скобки Ли корректно, то есть не зависит от выбора системы координат.
\end{proposition}

\begin{proof}
	Рассмотрим $\vec{v}$ и $\vec{w}$ как отображения $\M \to \R^3$. По определению дифференциала, имеем для этих отображений:
	\[
		d\vec{v}(\vec{w}) = \frac{\partial(V^i\vec{r}_i)}{\partial u^j}W^j = \br{\frac{\partial V^i}{\partial u^j}\vec{r}_i + V^i\vec{r}_{ij}}W^j.
	\]
	Аналогично,
	\[
		d\vec{w}(\vec{v}) = \br{\frac{\partial W^i}{\partial u^j}\vec{r}_i + W^i\vec{r}_{ij}}V^j.
	\]
	Отметим, что второе слагаемое в обоих случаях одно и то же. Отсюда,
	\[
		d\vec{w}(\vec{v}) - d\vec{v}(\vec{w}) = \br{V^j\frac{\partial W^i}{\partial u^j} - W^j\frac{\partial V^i}{\partial u^j}}\vec{r}_i = [\vec{v}, \vec{w}].
	\]

	Таким образом, мы выразили скобку Ли $[\vec{v}, \vec{w}]$ через инвариантные величины $d\vec{w}(\vec{v})$ и $d\vec{v}(\vec{w})$. Отметим, что каждая из этих двух величин не задаёт, вообще говоря, касательного поля к поверхности.
\end{proof}

Используя введённое понятие коммутатора векторных полей, приведённое выше рассуждение резюмируется следующим образом.

\begin{theorem}
	Два векторных поля $\vec{v}$ и $\vec{w}$ являются базисными векторными полями для некоторой локальной системы координат тогда и только тогда, когда они линейно независимы и коммутируют.
\end{theorem}

\begin{problem}
	Доказать, что выполнено \textit{тождество Якоби}:
	\[
		\big[[\vec{v}_1, \vec{v}_2], \vec{v}_3\big] +
		\big[[\vec{v}_2, \vec{v}_3], \vec{v}_1\big] +
		\big[[\vec{v}_3, \vec{v}_1], \vec{v}_2\big] \equiv \vec{0}
	\]
	для любых трёх векторных полей $\vec{v}_1$, $\vec{v}_2$, $\vec{v}_3$.
\end{problem}

\subsection{Поверхности постоянной отрицательной кривизны}

Уравнения Кодацци \eqref{eq:Codazzi} --- это, вообще говоря, сложные уравнения в частных производных первого порядка. Но есть специальный случай, в котором их удаётся решить, это поверхности с постоянной отрицательной гауссовой кривизной. Отметим, что при гомотетиях гауссова кривизна поверхности умножается всюду на одно и то же положительное число, так что достаточно рассмотреть случай $K \equiv -1$.

\begin{definition}
	Касательный вектор $\vec{\xi} \in \T_{\vec{x}}\M$ называется \textit{асимптотическим}, если $\II|_{\vec{x}}(\vec{\xi}) = 0$. Кривая называется \textit{асимптотической линией}, если её вектор скорости в каждой точки асимптотический.
\end{definition}

Если гауссова кривизна поверхности отрицательна, то отрицателен и определитель матрицы $\B$ второй квадратичной формы, а для квадратичной формы с отрицательным определителем на плоскости имеется ровно два асимптотических направления. Это можно понять двумя способами: вспомнить курс аналитической геометрии или посмотреть на формулу Эйлера \ref{theorem:EulerFormula} и воспользоваться соображениями непрерывности.

Обозначим эти два асимптотических направления через $\vec{e}_1$ и $\vec{e}_2$. Ясно при этом, что на самом деле естественным образом их занумеровать не получается. Но можно в произвольной точке как-то их занумеровать и продолжить на малую окрестность по непрерывности.

Итак, на поверхности отрицательной кривизны мы локально указали два векторных поля $\vec{e}_1$, $\vec{e}_2$ (с точностью до знака каждого из них и перестановки). Оказывается, что на поверхности \underline{постоянной} отрицательной кривизны эти поля коммутируют, что мы сейчас и покажем. Но сначала докажем общее утверждение.

% TODO: перенести (содержательно) эту лемму в раздел про векторные поля
\begin{lemma} \label{lemma:WeakBasis}
	Пусть $\vec{e}_1$, $\vec{e}_2$ --- два единичных линейно независимых векторных поля на поверхности $\M$. Тогда в окрестности каждой точки $\vec{x}_0$ на поверхности $\M$ можно выбрать локальные координаты $(u^1, u^2)$ таким образом, чтобы $\vec{x}_0 = \vec{r}(0, 0)$, $\vec{r}_1 = \vec{e}_1$ при $u^2 = 0$ и $\vec{r}_2 = \vec{e}_2$ всюду в некоторой окрестности точки $\vec{x}_0$.
\end{lemma}

Иными словами, любая линейно независимая пара векторных полей задаёт базис на некоторой достаточно малой простой дуге в заданной окрестности.

\begin{proof}
	Пусть $(u^1, u^2)$ --- произвольная система локальных координат в окрестности точки $\vec{x}_0$, причём $\vec{x}_0 = \vec{r}(u_0^1, u_0^2)$. Обозначим координаты векторов $\vec{e}_1$ и $\vec{e}_2$ по отношению к этой системе через $(E_1^1, E_1^2)$ и $(E_2^1, E_2^2)$ соответственно:
	\[
		\vec{e}_i = E^j_i\vec{r}_j.
	\]
	Решим уравнения
	\[
		\frac{d}{ds}\varphi^i(s) = E^i_1(\varphi^1(s), \varphi^2(s))
	\]
	с начальными условиями $\varphi^i(0) = u^i_0$ для $s$ из малой окрестности нуля. Геометрически это означает, что мы провели кривую $\gamma$ на поверхности $\M$ через точку $\vec{x}_0$ так, чтобы её вектором скорости в каждой точке $\vec{x}$ был вектор $\vec{e}_1(\vec{x})$. Параметр $s$ является натуральным на этой кривой (потому что поля единичные).
	% TODO: понять, зачем нам нужно, что s - именно НАТУРАЛЬНЫЙ параметр

	Теперь для каждого фиксированного $s$, для которого определены функции $\varphi^1$ и $\varphi^2$, решим уравнения
	\[
		\frac{d}{dt}\psi^i = E^i_2(\psi^1, \psi^2)
	\]
	с начальными условиями $\psi^i|_{t = 0} = \varphi^i(s)$. Таким образом, $\psi^1$, $\psi^2$ --- функции двух аргументов, $s$ и $t$: $\psi^i = \psi^i(s, t)$. По теореме о гладкой зависимости решения обыкновенного дифференциального уравнения от начальных условий, $\psi^i(s, t)$ --- гладкие функции. По построению имеем
	\[
		\left.
		\begin{pmatrix} % TODO: сделать нормально
			\begin{aligned}
				\frac{\partial\psi^1}{\partial s} \ \ \frac{\partial\psi^1}{\partial t}\\
				\frac{\partial\psi^2}{\partial s} \ \ \frac{\partial\psi^2}{\partial t}\\
			\end{aligned}
		\end{pmatrix}
		\right|_{(s, t) = (0, 0)} =
		\left.
		\begin{pmatrix}
			E_1^1 & E_2^1\\
			E_1^2 & E_2^2
		\end{pmatrix}
		\right|_{(u^1, u^2) = (u^1_0, u^2_0)}.
	\]

	Эта матрица невырожденна (потому что поля линейно независимы), поэтому локально можно сделать замену координат $u^1 = \psi^1(s, t)$, $u^2 = \psi^2(s, t)$. По построению будем иметь
	\begin{gather*}
		\frac{\partial}{\partial s}\vec{r}(\psi^1(s, t), \psi^2(s, t)) = (\vec{r}_iE_1^i)(\psi^1(s, t), \psi^2(s, t)) = \vec{e}_1(\psi^1(s, t), \psi^2(s, t))\ \text{при $t = 0$},\\
		\frac{\partial}{\partial t}\vec{r}(\psi^1(s, t), \psi^2(s, t)) = (\vec{r}_iE_2^i)(\psi^1(s, t), \psi^2(s, t)) = \vec{e}_2(\psi^1(s, t), \psi^2(s, t))\ \text{при всех $s$, $t$}.
	\end{gather*}
\end{proof}

Далее считаем, что координаты введены, как в лемме \ref{lemma:WeakBasis}. В этих координатах мы знаем вид вид первой и второй квадратичной форм. На всей области имеем
\[
	\G =
	\begin{pmatrix}
		g_{11} & g_{12}\\
		g_{12} & 1
	\end{pmatrix},\quad
	\B =
	\begin{pmatrix}
		b_{11} & b_{12}\\
		b_{12} & 0
	\end{pmatrix}.
\]

При $u^2 = 0$ у матрицы $\G$ на диагонали стоят единицы, а у матрицы $\B$ --- нули. Более того, мы знаем, что $\det\B / \det\G = -1$ (из формулы для гауссовой кривизны), отсюда $\det\B = -1$. Поэтому на самом деле вне диагонали в матрице $\B$ стоят $\pm 1$. Мы можем считать, что там стоят $1$, потому что если это не так, можно сменить знак у координаты $u^2$:
\begin{equation} \label{eq:GBu20}
	\G|_{u^2 = 0} =
	\begin{pmatrix}
		1 & \ast\\
		\ast & 1
	\end{pmatrix},\quad
	\B|_{u^2 = 0} =
	\begin{pmatrix}
		0 & 1\\
		1 & 0
	\end{pmatrix}.
\end{equation}

На всей области мы знаем (из $K = -1$), что $b_{12} = \sqrt{\det\G}$ (опять же, здесь надо писать $\pm\det\G$, но мы можем поменять знак у какой-то координаты), где $\det\G = g_{11} - g_{12}^2$.

Итак, у нас есть два уравнения Кодацци \eqref{eq:Codazzi}:
\[
	\frac{\partial b_{12}}{\partial u^1} - \frac{\partial b_{11}}{\partial u^2} + b_{s1}\Gamma_{12}^s - b_{s2}\Gamma_{11}^s = 0,\quad
	\frac{\partial b_{22}}{\partial u^1} - \frac{\partial b_{21}}{\partial u^2} + b_{s1}\Gamma_{22}^s - b_{s2}\Gamma_{21}^s = 0,
\]
и три неизвестных функции $g_{11}$, $g_{12}$ и $b_{11}$ (напомним, что $b_{12}$ мы уже выразили). Здесь нужно сделать трюк: предположим, что $g_{12}$ --- известная функция, и будем пытаться восстановить через неё $g_{11}$ и $b_{11}$. В уравнениях Кодацци уже можно выполнить некоторые подстановки, при этом нам будет удобно\footnotemark{} обозначить $g \vcentcolon = \det\G$.
\begin{gather*}
	\frac{\partial\sqrt{g}}{\partial u^1} - \frac{\partial b_{11}}{\partial u^2} + b_{11}\Gamma_{12}^1 + b_{12}\Gamma_{12}^2 - b_{12}\Gamma_{11}^1 = 0,\\
	-\frac{\partial\sqrt{g}}{\partial u^2} + b_{11}\Gamma_{22}^1 + b_{12}\Gamma_{22}^2 - b_{12}\Gamma_{21}^2 = 0.
\end{gather*}

\footnotetext{Мне долго удавалось избегать этого обозначения (оно мне просто не нравится), но здесь приходится его принять, иначе совсем неудобно.}

Мы хотим, чтобы на неизвестные функции $g_{11}$ и $b_{11}$ не было производных по $u^1$. Потому что при $u^2 = 0$ у нас есть начальные условия \eqref{eq:GBu20}, и мы сможем воспользоваться теоремой о существовании и единственности решения для обыкновенного дифференциального уравнения. А сейчас у нас уравнения в частных производных.

Итак, мы хотим найти в наших уравнениях производные $\ds\frac{\partial g_{11}}{\partial u^1}$ и $\ds\frac{\partial b_{11}}{\partial u^1}$. Сразу отметим, что вторых точно нигде не будет, поэтому ищем первые. Рассмотрим сначала первое уравнение. В нём сразу видим частную производную по $u^1$ и пишем
\begin{equation} \label{eq:dgdu1}
	\frac{1}{2\sqrt{g}}\frac{\partial g_{11}}{\partial u^1} + \ldots = 0.
\end{equation}
(Мы хотим дописать в это уравнение всё, что найдём с частными производными $\partial g_{11} / \partial u^1$ и убедиться, что всё сокращается.)

Ещё нам стоит бояться символов Кристоффеля, ведь на самом деле они здесь определяются через формулы \eqref{eq:ChristoffelIdentity}, в которых могут присутствовать частные производные $\ds\frac{\partial g_{11}}{\partial u^1}$. Проверяем все символы Кристоффеля по очереди.
\[
	\Gamma_{12}^k = \frac{g^{kl}}{2}\br{\frac{\partial g_{1l}}{\partial u^2} + \frac{\partial g_{2l}}{\partial u^1} - \frac{\partial g_{12}}{\partial u^l}}
\]
--- здесь всё хорошо, поэтому $\Gamma_{12}^1$ и $\Gamma_{12}^2$ нас более не интересуют. Проверяем оставшийся символ Кристоффеля в первом уравнении:
\[
	\Gamma_{11}^1 = \frac{g^{1l}}{2}\br{\frac{\partial g_{1l}}{\partial u^1} + \frac{\partial g_{1l}}{\partial u^1} - \frac{\partial g_{11}}{\partial u^l}}.
\]
Видим, что при $l = 1$ получаются искомые производные, а при $l = 2$ их не будет. Дописывая их в уравнение \eqref{eq:dgdu1}, получаем:
\[
	\frac{1}{2\sqrt{g}}\frac{\partial g_{11}}{\partial u^1} - \sqrt{g}\frac{1}{2g}\frac{\partial g_{11}}{\partial u^1} = 0.
\]
(Явная формула для обратной матрицы даёт $g^{11} = g^{-1}$.) Видим, что всё сокращается.

У каждого символа Кристоффеля во втором уравнении один из индексов равен $2$, поэтому $\partial g_{11} / \partial u^1$ там появиться не может (это легко увидеть, взглянув на тождества Кристоффеля).

Таким образом, в случае поверхностей постоянной отрицательной гауссовой кривизны уравнения Кодацци являются обыкновенными дифференциальными уравнениями вида
\begin{gather*}
	\frac{\partial g_{11}}{\partial u^2} = \ldots\\
	\frac{\partial b_{11}}{\partial u^2} = \ldots
\end{gather*}
с начальными условиями \eqref{eq:GBu20}. Но нас интересует не только возможность их решения, но и конкретный вид решений. При этом находить сами уравнения мы не хотим (надо в лоб расписывать символы Кристоффеля и подставлять; можно, но не хочется).

Появляется <<Бог из машины>>: а вдруг в качестве решения подойдут $g_{11} \equiv 1$, $b_{11} \hm\equiv 0$? (Мы просто взяли начальные условия и предположили, что они подойдут в качестве решений на всей области.) Если это решения, то поскольку эти функции находятся из обыкновенных дифференциальных уравнений, то никаких других решений быть не может.

Итак, мы хотим проверить, что уравнениям Кодацци удовлетворяют формы
\[
	\G =
	\begin{pmatrix}
		1 & g_{12}\\
		g_{12} & 1
	\end{pmatrix},\quad
	\B =
	\begin{pmatrix}
		0 & \sqrt{g}\\
		\sqrt{g} & 0
	\end{pmatrix},
\]
где $g_{12}$ --- произвольная гладкая функция и $g = 1 - g_{12}^2$.

Нужно посчитать все символы Кристоффеля, но нашем случае это сделать легко, ведь все элементы матрицы $\G$, кроме $g_{12}$ --- константы, и их производные обнуляются. Так что можем сразу написать (опять пользуемся явной формулой для обратной матрицы):
\begin{equation} \label{eq:ChristoffelNegativeK}
    \begin{gathered}
        \Gamma_{11}^1 = -\frac{g_{12}}{g} \frac{\partial g_{12}}{\partial u^1}, \quad \Gamma_{22}^1 = \frac{1}{g} \frac{\partial g_{12}}{\partial u^2}, \quad \Gamma_{11}^2 = \frac{1}{g} \frac{\partial g_{12}}{\partial u^1}, \quad \Gamma_{22}^2 = -\frac{g_{12}}{g} \frac{\partial g_{12}}{\partial u^2}, \\
        \Gamma_{12}^1 = \Gamma_{21}^1 = \Gamma_{12}^2 = \Gamma_{21}^2 = 0.
    \end{gathered}
\end{equation}
Подставляем в первое уравнение:
\[
	-\frac{g_{12}}{\sqrt{g}}\frac{\partial g_{12}}{\partial u^1} + \sqrt{g}\frac{g_{12}}{g}\frac{\partial g_{12}}{\partial u^1} = 0
\]
--- всё сократилось. Аналогично для второго уравнения.

Итак, мы получили локально
\[
	\I = (du^1)^2 + (du^2)^2 + 2g_{12}\,du^1du^2,\quad \II = 2\sqrt{g}du^1du^2,
\]
где про $g_{12}$ мы пока ничего не знаем. Таким образом, мы доказали, что в случае поверхностей постоянной отрицательной гауссовой кривизны асимптотические направления локально задают базисные поля, а значит, коммутируют. Напомним, что на нашей координатной сетке из асимптотических линий на каждой линии введён натуральный параметр (см. доказательство леммы \ref{lemma:WeakBasis}). Такие координатные системы называются \textit{сетями Чебышёва}\footnotemark.

\footnotetext{Насколько я знаю, впервые П.\,Л. Чебышёв ввёл это понятие в известном (в частности, по бородатому анекдоту) докладе <<О кройке одежды>>. Дело в том, что координатные линии сетей Чебышёва ведут себя, как нерастяжимые тканевые нити (которые при этом могут изгибаться и менять углы друг относительно друга).}

У нас осталось одна неизвестная функция $g_{12}$ и уравнение Гаусса \eqref{eq:Gauss}, на которое мы пока не смотрели. Далее мы подставим найденные матричные элементы в это уравнение и получим условие на функцию $g_{12}$. Но перед этим отметим следующее: мы знаем, что
\[
	g = 1 - g_{12}^2 = b_{12}^2.
\]
Иными словами, $g_{12}^2 + b_{12}^2 = 1$. Тогда мы можем написать
\begin{equation} \label{eq:CosSin}
	g_{12} = \cos\omega,\ b_{12} = \sin\omega,
\end{equation}
где $\omega$ --- угол между асимптотическими линиями (так как $\cos\omega = g_{12} = \langle\vec{e}_1, \vec{e}_2\rangle$). Напомним общий вид выражения гауссовой кривизны $K$ через метрику:
\[
	K = \frac{g_{1k}}{g}\br{\frac{\partial\Gamma^k_{22}}{\partial u^1} - \frac{\partial\Gamma_{21}^k}{\partial u^2} + \Gamma_{k1}^s\Gamma^k_{22} - \Gamma_{s2}^k\Gamma_{21}^s}.
\]
Подставляем сюда формулы \eqref{eq:ChristoffelNegativeK}:
\begin{multline*}
	-g = g_{1k}\br{\frac{\partial\Gamma^k_{22}}{\partial u^1} - \frac{\partial\Gamma_{21}^k}{\partial u^2} + \Gamma_{k1}^s\Gamma^k_{22} - \Gamma_{s2}^k\Gamma_{21}^s} =\\ = \frac{\partial\Gamma_{22}^1}{\partial u^1} + \Gamma_{11}^1\Gamma_{22}^1 + g_{12}\br{\frac{\partial \Gamma_{22}^2}{\partial u^1} + \Gamma_{11}^2\Gamma_{22}^1} = \frac{\partial\Gamma_{22}^1}{\partial u^1} + g_{12}\frac{\partial\Gamma_{22}^2}{\partial u^1}.
\end{multline*}
Теперь пользуемся подстановкой \eqref{eq:CosSin}:
\begin{gather*}
	g = b_{12}^2 = \sin^2\omega,\\
	\Gamma_{22}^1 = \frac{1}{g}\frac{\partial g_{12}}{\partial u^2} = \frac{1}{\sin^2\omega}{\partial\cos\omega}{\partial u^2} = -\frac{1}{\sin\omega}\frac{\partial\omega}{\partial u^2},\\
	\Gamma_{22}^2 = -\frac{g_{12}}{g}\frac{\partial g_{12}}{\partial u^2} = -\frac{\cos\omega}{\sin^2\omega}\frac{\partial\cos\omega}{\partial u^2} = \ctg\omega\frac{\partial\omega}{\partial u^2}.
\end{gather*}
В итоге получаем
\begin{multline*}
	0 = \frac{\partial\Gamma_{22}^1}{\partial u^1} + g_{12}\frac{\partial\Gamma_{22}^2}{\partial u^1} + g = -\frac{\partial}{\partial u^1}\br{\frac{1}{\sin\omega}\frac{\partial\omega}{\partial u^2}} + {}\\{} + \cos\varphi\frac{\partial}{\partial u^1} \cdot \br{\ctg\omega\frac{\partial\omega}{\partial u^2}} + \sin^2\omega = -\sin\omega \cdot \frac{\partial^2\omega}{\partial u^1\partial u^2} + \sin^2\omega,
\end{multline*}
что равносильно следующему (поскольку $\sin\omega \ne 0$):
\begin{equation} \label{eq:sinGordon}
	\frac{\partial^2\omega}{\partial u^1\partial u^2} = \sin\omega.
\end{equation}

Все наши рассуждения можно сформулировать в виде следующей теоремы.

\begin{theorem}
	\begin{enumerate}[nolistsep, label=(\arabic*)]
		\item На поверхности с постоянной гауссовой кривизной $K \equiv -1$ в окрестности каждой точки существует система координат $(u^1, u^2)$, в которой первая и вторая квадратичные формы имеют вид
			\begin{equation} \label{eq:IIINegativeK}
				\I = (du^1)^2 + (du^2)^2 + 2\cos\omega(u^1, u^2)\,du^1du^2,\quad \II = 2\sin\omega(u^1, u^2)\,du^1du^2,
			\end{equation}
			причём эта система координат определена однозначно с точностью до перестановки координат, их сдвигов на константы и смены знака любой из них.
		\item В системе координат, указанной в предыдущем пункте, функция $\omega$ удовлетворяет \textit{уравнению $\sin$-Гордон}\footnotemark \label{eq:sinGordon}.
		\item Для любого этого уравнения с $\sin\omega \ne 0$ существует поверхность постоянной кривизны $K \equiv -1$ с первой и второй квадратичными формами вида \eqref{eq:IIINegativeK}.
	\end{enumerate}
\end{theorem}

\footnotetext{Уравнение $\sin$-Гордон играет важную роль в теории солитонов. Я не осознаю, что это значит и не думаю, что должен, но об этом упоминается везде, где написано про это уравнение. Я лишь продолжаю добрую традицию.}

Простейшим нетривиальным решением уравнения $\sin$-Гордон является
\[
	\omega = 4\arctg e^{u^1 + u^2}.
\]
Оно соответствует псевдосфере Бельтрами.

