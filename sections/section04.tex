\section{Основные уравнения в теории поверхностей}

\epigraph{Эти формулы надо запомнить, вот как хотите.\footnotemark}{А.\,А. Гайфуллин}

\footnotetext{Речь шла о формулах \eqref{eq:ChristoffelIdentity} и \eqref{eq:CovariantFormula}.}

\subsection{Деривационные уравнения. Тождества Кристоффеля}

Мы хотим написать для поверхностей что-то похожее на формулы Френе, то есть наша цель --- научиться дифференцировать векторы
\[
	\vec{r}_1 \vcentcolon = \frac{\partial\vec{r}}{\partial u^1},\quad
	\vec{r}_2 \vcentcolon = \frac{\partial\vec{r}}{\partial u^2},
\]
для этого нам будет удобно обозначить
\[
	\vec{r}_{ij} \vcentcolon = \frac{\partial^2\vec{r}}{\partial u^i\partial u^j}.
\]

Векторы $(\vec{r}_1, \vec{r}_2, \vec{n})$ образуют базис в каждой точке поверхности, поэтому каждый вектор $\vec{r}_{ij}$ в нём как-то записывается. Заметим, что коэффициент при $\vec{n}$ мы уже знаем --- это соответствующий элемент матрицы второй квадратичной формы $b_{ij}$. Действительно, ведь по определению $b_{ij} = \langle\vec{r}_{ij}, \vec{n}\rangle$.

\begin{definition}
	Коэффициенты $\Gamma_{ij}^k = \Gamma_{ji}^k$ в разложении
	\begin{equation} \label{eq:DerivativeGauss}
		\vec{r}_{ij} = \Gamma_{ij}^k\vec{r}_k + b_{ij}\vec{n}
	\end{equation}
	называются \textit{символами Кристоффеля}.
\end{definition}

\begin{lemma}[Тождества Кристоффеля]
	Символы Кристоффеля однозначно определяются метрикой на поверхности. Более точно, верна следующая формула:
	\begin{equation} \label{eq:ChristoffelIdentity}
		\Gamma_{ij}^k = \frac{g^{kl}}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}},
	\end{equation}
	где $g^{kl}$ обозначают элементы матрицы $\G^{-1}$.
\end{lemma}

\begin{proof}
	Напишем
	\begin{equation} \label{eq:FirstFormula}
		\langle\vec{r}_{ij}, \vec{r}_l\rangle = \Gamma_{ij}^s\langle\vec{r}_s, \vec{r}_l\rangle = \Gamma_{ij}^sg_{sl}
	\end{equation}
	и
	\[\begin{tikzcd}
		{\ds\frac{\partial g_{il}}{\partial u^j}} & {\ds\frac{\partial}{\partial u^j}\langle\vec{r}_i, \vec{r}_l\rangle} & {\langle\vec{r}_{ij}, \vec{r}_l\rangle + \langle\vec{r}_i, \vec{r}_{jl}\rangle.}
		\arrow[equals, from=1-1, to=1-2]
		\arrow[equals, from=1-2, to=1-3]
	\end{tikzcd}\]
	Последнюю формулу напишем три раза, сдвигая координаты:
	\begin{gather} \label{eq:SecondFormula}
		\frac{\partial g_{il}}{\partial u^j} = \langle\vec{r}_{ij}, \vec{r}_l\rangle \phantom{{} + \langle\vec{r}_j, \vec{r}_{il}\rangle} + \langle\vec{r}_i, \vec{r}_{jl}\rangle\nonumber,\\
		\frac{\partial g_{jl}}{\partial u^i} = \langle\vec{r}_{ij}, \vec{r}_l\rangle + \langle\vec{r}_j, \vec{r}_{il}\rangle \phantom{{} + \langle\vec{r}_i, \vec{r}_{jl}\rangle}\nonumber,\\
		\frac{\partial g_{ij}}{\partial u^l} = \phantom{\langle\vec{r}_{ij}, \vec{r}_l\rangle + {}} \langle\vec{r}_{il}, \vec{r}_j\rangle + \langle\vec{r}_i, \vec{r}_{jl}\rangle.
	\end{gather}
	Сложим первые две строки из них и вычтем третью, получим
	\begin{gather*}
		\langle\vec{r}_{ij}, \vec{r}_l\rangle = \frac{1}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}}.
	\end{gather*}
	Теперь подставляем \eqref{eq:FirstFormula}:
	\[
		g_{ls}\Gamma_{ij}^s = \frac{1}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}}.
	\]
	Домножаем обе части на $g^{kl}$ и суммируем по $k$. Слева получим $g^{kl}g_{ls}\Gamma^s_{ij} = \delta^k_s\Gamma^s_{ij} = \Gamma^k_{ij}$:
	\[
		\Gamma_{ij}^k = \frac{g^{kl}}{2}\br{\frac{\partial g_{il}}{\partial u^j} + \frac{\partial g_{jl}}{\partial u^i} - \frac{\partial g_{ij}}{\partial u^l}}.
	\]
\end{proof}

Отметим, что попутно мы доказали ещё один набор важных формул. Можно напрямую подставить в \eqref{eq:SecondFormula} формулы вида \eqref{eq:FirstFormula}, получим следующее.

\begin{lemma}
	Выполнены следующие тождества:
	\begin{equation} \label{eq:AlmostCristoffelIdentity}
		\frac{\partial g_{ij}}{\partial u^k} = g_{js}\Gamma^s_{ik} + g_{is}\Gamma^s_{jk}.
	\end{equation}
\end{lemma}

Следует отметить, что символы Кристоффеля не задают никакого тензора в касательном пространстве к поверхности.

\begin{problem}
	Доказать, что при переходе к другим локальным координатам $(\widetilde{u}^1, \widetilde{u}^2)$ символы Кристоффеля преобразуются по следующему закону:
	\[
		\widetilde{\Gamma}_{ij}^k = \Gamma_{pq}^r\frac{\partial \widetilde{u}^k}{\partial u^r}\frac{\partial u^p}{\partial \widetilde{u}^i}\frac{\partial u^q}{\partial \widetilde{u}^j} + \frac{\partial\widetilde{u}^k}{\partial u^p}\frac{\partial^2u^p}{\partial \widetilde{u}^i\partial \widetilde{u}^j}.
	\]
\end{problem}

\noindent
Уравнения \eqref{eq:DerivativeGauss} с подстановкой \eqref{eq:ChristoffelIdentity} называются \textit{деривационными уравнениями Гаусса}.

Теперь хотим дифференцировать вектор $\vec{n}$. Обозначим
\[
	\vec{n}_1 \vcentcolon = \frac{\partial \vec{n}}{\partial u^1}\quad\text{и}\quad\vec{n}_2 \vcentcolon = \frac{\partial \vec{n}}{\partial u^2}.
\]

Поскольку вектор $\vec{n}$ имеет постоянную длину, оба этих вектора ортогональны $\vec{n}$, а значит, выражаются через базисные векторы $\vec{r}_1$, $\vec{r}_2$ касательного пространства в соответствующей точке. Пока напишем формально:
\begin{equation} \label{eq:DerivativeWeingarten}
	\vec{n}_i = c^j_i\vec{r}_j,
\end{equation}
позже мы придадим коэффициентам $c^j_i$ какой-то смысл.

\begin{lemma}
	Имеет место равенство
	\begin{equation} \label{eq:WeingartenIdentity}
		c^j_i = -g^{jk}b_{ki},
	\end{equation}
	где $g^{jk}$ обозначают элементы матрицы $\G^{-1}$.
\end{lemma}

\begin{proof}
	Векторы $\vec{n}$ и $\vec{r}_k$ ортогональны (по построению), поэтому
	\[
		\langle\vec{n}_i, \vec{r}_k\rangle = -\langle\vec{n}, \vec{r}_{ik}\rangle = -b_{ik}.
	\]
	Подставляя выражение для $\vec{n}_i$, получаем
	\[\begin{tikzcd}
		{c^j_i\langle\vec{r}_j, \vec{r}_k\rangle} & {c^j_ig_{jk}} & {-b_{ik}}
		\arrow[equals, from=1-1, to=1-2]
		\arrow[equals, from=1-2, to=1-3]
	\end{tikzcd}\]
	Переписываем в матричном виде (с учётом $b_{ik} = b_{ki}$):
	\[
		\G C = -\B,\,\text{где }C = (c^j_i).
	\]
	Из него можно выразить матрицу $C$ как $C = -\G^{-1}\B$, или, в обозначениях Эйнштейна,
	\[
		c^j_i = -g^{jk}b_{ki}.
	\]
\end{proof}

Уравнения \eqref{eq:DerivativeWeingarten} с подстановкой \eqref{eq:WeingartenIdentity} называются \textit{деривационными уравнениями Вайнгартена}. Вместе, уравнения
\begin{equation} \label{eq:DerivativeEquations}
	\begin{cases}
		\vec{r}_{ij} = \Gamma_{ij}^k\vec{r}_k + b_{ij}\vec{n},\\
		\vec{n}_i = c^j_i
	\end{cases}
\end{equation}
называются \textit{деривационными уравнениями Гаусса "---Вайнгартена}. Заметим, что все коэффициенты этих уравнений выражаются через первую и вторую квадратичные формы поверхности. Так что, разрешив эти уравнения относительно $\vec{r}$, по первой и второй квадратичной форме мы восстановим поверхность. Так же мы раньше восстанавливали пространственные кривые по кривизне и кручению. Отметим, однако, что если кривую можно было восстановить про произвольным гладким функциям кривизны и кручения, то теперь для деривационных уравнений имеется нетривиальное условие совместности. Мы вернёмся к этому позже в следующем разделе.

Теперь обсудим смысл коэффициентов $c^j_i$. Разумеется, они зависят от параметризации, но матрица $C$ преобразуется как матрица линейного оператора в касательном пространстве к поверхности, так как $C = -\G^{-1}\B$.

\begin{definition}
	\textit{Сферическим отображением} гладкой поверхности $\M$ называется отображение $\nu\colon \M \to S^2$, которое каждой точке $\vec{x}$ поверхности ставит в соответствие единичный вектор нормали $\vec{n}$ к соответствующей касательной плоскости $\T_{\vec{x}}\M$.
\end{definition}

Это отображение, строго говоря, задаёт отображение $\nu$ лишь с точностью до знака. Знак $\vec{n}$ выбирается таким, чтобы тройка векторов $(\vec{r}_1, \vec{r}_2, \vec{n})$ была положительно ориентированной.

\begin{proposition}
	Для любой точки $\vec{x}$ поверхности $\M$ касательные пространства $\T_{\vec{x}}\M$ и $\T_{\nu(\vec{x})}S^2$ совпадают.
\end{proposition}

\begin{proof}
	Вектор $\vec{\xi}$ лежит в касательном пространстве $\T_{\vec{x}}\M$ тогда и только тогда, когда $\vec{\xi} \perp \vec{n}$. При этом же условии он лежит в касательном пространстве $\T_{\nu(\vec{x})}S^2$.
\end{proof}

Последнее предложение означает, что дифференциал $d\nu|_{\vec{x}}$ сферического отображения можно понимать как линейный оператор на касательном пространстве. Сопоставляя определение дифференциала и деривационные формулы Вайнгартена $\vec{n}_i = -g^{jk}b_{ki}\vec{r}_j$, мы немедленно получаем следующее утверждение.

\begin{proposition}
	Оператор $d\nu$ имеет в базисе $\vec{r}_1$, $\vec{r}_2$ матрицу $C = (c^j_i)$, элементы которой определены формулами \eqref{eq:WeingartenIdentity}.
\end{proposition}

\begin{definition}
	Оператор, заданный в касательном пространстве матрицей $C$, называется \textit{оператором Вайнгартена}.
\end{definition}

\begin{theorem} \label{theorem:Weingarten}
	Оператор Вайнгартена самосопряжён относительно скалярного произведения, заданного в $\T_{\vec{x}}\M$ первой квадратичной формой. Векторы главных направлений $\vec{\xi}_1$ и $\vec{\xi}_2$ являются для него собственными, а соответствующие им собственные значения суть главные кривизны, взятые с обратным знаком: $-\lambda_1$, $-\lambda_2$. Кроме того, имеют место равенства
	\[
		\det\br{d\nu|_{\vec{x}}} = \frac{\det\B}{\det\G} = K.
	\]
\end{theorem}

\noindent
Эта теорема доказывается прямой проверкой всех определений.

\subsection{Совместность деривационных уравнений и теорема Бонне}

Запишем деривационные уравнения \eqref{eq:DerivativeEquations} в матричном виде:
\[
	\frac{\partial}{\partial u^i}
	\begin{pmatrix}
		\vec{r}_1 & \vec{r}_2 & \vec{n}
	\end{pmatrix} =
	\begin{pmatrix}
		\vec{r}_1 & \vec{r}_2 & \vec{n}
	\end{pmatrix}A_i,
\]
где
\[
	A_i =
	\begin{pmatrix}
		\Gamma_{i1}^1 & \Gamma_{i1}^2 & -b_{ik}g^{k1}\\
		\Gamma_{i2}^1 & \Gamma_{i2}^2 & -b_{ik}g^{k2}\\
		b_{i1} & b_{i2} & 0
	\end{pmatrix}.
\]

Если рассматривать эти уравнения как пару дифференциальных уравнений на матрицу $X = (\vec{r}_1, \vec{r}_2, \vec{n})$, то условие совместности \eqref{eq:Darboux} из теоремы Дарбу для них принимает вид
\[
	\frac{\partial}{\partial u^1}A_2 + A_1A_2 = \frac{\partial}{\partial u^2}A_1 + A_2A_1,
\]
что можно переписать как
\begin{equation} \label{eq:Jointness}
	\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} = [A_1, A_2],
\end{equation}
где $[A_1, A_2] = A_1A_2 - A_2A_1$ --- коммутатор матриц.

В формулировке следующей теоремы поверхность понимается в более широком смысле, чем в наших определениях. А именно, поверхности разрешается иметь самопересечения.

\begin{theorem}[Бонне]
	Пусть $g_{ij}(u^1, u^2)$, $b_{ij}(u^1, u^2)$, где $i, j = 1, 2$, --- набор гладкий функций в замкнутой односвязной области $\Omega \subset \R^2$, удовлетворяющие условиям: матрицы $G = (g_{ij})$ и $B = (b_{ij})$ симметричны для всех точек $(u^1, u^2) \in \Omega$, причём матрица $G$ положительно определена. Тогда
	\begin{enumerate}[nolistsep, label=(\arabic*)]
		\item в $\R^3$ существует поверхность $\M$ с регулярной параметризацией $\Omega \to \M$, для которой первая и вторая квадратичные формы равны
			\[
				\I = g_{ij}du^idu^j,\quad\II = b_{ij}du^idu^j
			\]
			тогда и только тогда, когда функции $g_{ij}$, $b_{ij}$ ($i, j = 1, 2$) удовлетворяют уравнениям Гаусса "---Кодацци;
		\item если поверхность с такими квадратичными формами существует, то она единственна с точностью до движения всего пространства $\R^3$.
	\end{enumerate}
\end{theorem}

\begin{proof}
	Чтобы не углубляться в технические детали, проведём доказательство в том случае, когда область $\Omega$ является квадратом $[0; 1] \times [0; 1]$.

	Покажем необходимость условий \eqref{eq:Jointness}. Пусть данные коэффициенты $(g_{ij})$ и $(b_{ij})$ соответствуют некоторой поверхности в $\R^3$ с параметризацией $\vec{r}(u^1, u^2)$. Тогда матрица $X =
	\begin{pmatrix}
		\vec{r}_1 & \vec{r}_2 & \vec{n}
	\end{pmatrix}$ удовлетворяет паре уравнений
	\[
		\frac{\partial}{\partial u^1}X = XA_1,\quad 
		\frac{\partial}{\partial u^2}X = XA_2,
	\]
	то есть, казабось бы, мы умеем решать систему только при одном начальном условии $X|_{(0, 0)}$, а хотим при всех (см. условие теоремы Дарбу \ref{theorem:Darboux}). Но заметим, что уравнения \eqref{eq:Jointness} линейные, а потом замена $X \mapsto CX$ (где $C$ --- любая матрица) переводит одно системы решение в другое. Так что возможность решить систему при каком-то одном начальном условии даёт нам возможность решить её при любых начальных условиях\footnotemark.
	
	\footnotetext{Отметим, что это общая специфика любых \underline{линейных} систем дифференциальных уравнений.}

	Теперь обсудим единственность восстановления с точностью до движений $\R^3$. Векторы $\vec{r}_1$, $\vec{r}_2$ и $\vec{n}$ удовлетворяют системе обыкновенных дифференциальных уравнений
	\[
		\frac{\partial}{\partial u^1}\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} A_1,
	\]
	которое полностью определяет их в точках вида $(u^1, 0)$ для всех $u^1$ при известных начальных значениях $\vec{r}_1|_{(0, 0)}$, $\vec{r}_2|_{(0, 0)}$, $\vec{n}|_{(0, 0)}$. Далее, из уравнения
	\[
		\frac{\partial}{\partial u^2}\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{r}_1 & \vec{r}_2 & \vec{n}
		\end{pmatrix} A_2
	\]
	значения $\vec{r}_1$, $\vec{r}_2$ и $\vec{n}$ находятся во всех точках $(u^1, u^2) \in \Omega$. Аналогичным образом, параметризация $\vec{r}(u^1, u^2)$ находится однозначно при известных $\vec{r}_1$ и $\vec{r}_2$, если известно начальное условие $\vec{r}|_{(0, 0)}$.

	Таким образом, вся неоднозначность восстановления поверхности сводится к выбору начальных значений $\vec{r}_{(0, 0)}$, $\vec{r}_1|_{(0, 0)}$, $\vec{r}_2|_{(0, 0)}$ и $\vec{n}|_{(0, 0)}$. При этом нам жёстко задана матрица Грама этих векторов. Поэтому единственная свобода выбора начальных условий --- это движения всего пространства $\R^3$.

	Перейдём к сложной части --- достаточности. Согласно теореме Дарбу \eqref{theorem:Darboux} условия совместности \eqref{eq:Jointness} дают возможность найти векторы $\vec{v}_1$, $\vec{v}_2$ и $\vec{n}$, удовлетворяющие уравнениям
	\begin{equation} \label{eq:DerivativeMatrix}
		\frac{\partial}{\partial u^1}
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}A_1,\quad
		\frac{\partial}{\partial u^2}
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix} =
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}A_2
	\end{equation}
	в некоторой окрестности точки $(u^1, u^2) = (0, 0)$ при данном начальном условии. Так что вопрос здесь только в том, чтобы решить эти уравнения на всём квадрате $\Omega$, а не только в малой окрестности начала координат. В данном случае решение распространяется на всю область, так как рассматриваемые уравнения линейны, а линейные уравнения решаются <<сколь угодно далеко>>. Здесь также важно, что процедура восстановления векторов $\vec{v}_1$, $\vec{v}_2$ и $\vec{n}$, описанная на предыдущем шаге (где эти же векторы обозначались через, соответственно, $\vec{r}_1$, $\vec{r}_2$ и $\vec{n}$), в точности повторяет процедуру построения решения в доказательстве теоремы Дарбу \ref{theorem:Darboux}. Как там было показано, при выполнении условий совместности, такая процедура приводит к решению обоих уравнений системы.

	Далее, собственно для восстановления поверхности нужно при уже известных вектора $\vec{v}_1$, $\vec{v}_2$ решить уравнения
	\begin{equation} \label{eq:SurfaceRecuperation}
		\frac{\partial}{\partial u^1}\vec{r} = \vec{v}_1,\quad
		\frac{\partial}{\partial u^2}\vec{r} = \vec{v}_2.
	\end{equation}
	Условие совместности для этой системы имеет вид
	\[
		\frac{\partial}{\partial u^2}\vec{v}_1 = \frac{\partial}{\partial u^1}\vec{v}_2
	\]
	(см. пример \ref{example:SimpleDiffJointness}). Оно выполнено, так как верны формулы
	\[
		\frac{\partial\vec{v}_i}{\partial u^j} = \Gamma_{ij}^k\vec{v}_k + b_{ij}\vec{n}.
	\]
	(Они, в свою очередь, верны просто в силу уравнений \eqref{eq:DerivativeMatrix}.) Действительно, ведь правые части этих формул симметричны по $i$ и $j$, а значит, и левые тоже. Таким образом, локальных препятствий к решению системы \eqref{eq:SurfaceRecuperation} нет, а существование решения на всём квадрате снова следует из вида уравнений, здесь правая часть не зависит от $\vec{r}$, и они решаются простым интегрированием.

	Итак, мы построили решения системы 
	\[
		\begin{cases}
			\ds\frac{\partial}{\partial u^i}
			\begin{pmatrix}
				\vec{v}_1 & \vec{v}_2 & \vec{n}
			\end{pmatrix} =
			\begin{pmatrix}
				\vec{v}_1 & \vec{v}_2 & \vec{n}
			\end{pmatrix}A_i,\\
			\ds\frac{\partial \vec{r}}{\partial u^j} = \vec{v}_j
		\end{cases}
	\]
	с начальными условиями на $\vec{r}_{(0, 0)}$, $\vec{r}_1|_{(0, 0)}$, $\vec{r}_2|_{(0, 0)}$ и $\vec{n}|_{(0, 0)}$. Теперь нас беспокоит следующий вопрос --- а действительно ли данные нам $g_{ij}$ и $b_{ij}$ ($i, j = 1, 2$) являются коэффициентами, соответственно, первой и второй квадратичной формы построенной нами поверхности?

	Рассмотрим матрицу $\widetilde{G}$ первой квадратичной формы нашей поверхности, то есть матрицу Грама векторов $(\vec{r}_1, \vec{r}_2, \vec{n})$:
	\[
		\widetilde{G} \vcentcolon =
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}^t
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}.
	\]
	В силу уравнений \eqref{eq:DerivativeMatrix} напишем:
	\[
		\frac{\partial}{\partial u^i}\widetilde{G} = 
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}^t_{u^i}
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix} + 
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}^t
		\begin{pmatrix}
			\vec{v}_1 & \vec{v}_2 & \vec{n}
		\end{pmatrix}_{u^i} = A_i^t\widetilde{G} + \widetilde{G}A_i.
	\]
	А теперь рассмотрим матрицу
	\[
		\widehat{G} \vcentcolon =
		\begin{pmatrix}
			g_{11} & g_{12} & 0\\
			g_{12} & g_{22} & 0\\
			0 & 0 & 1
		\end{pmatrix}.
	\]
	Оказывается, для неё выполнены те же формулы.

	\begin{lemma} \label{lemma:Gui}
		Выполнено
		\[
			A_i^t\widehat{G} + \widehat{G}A_i = \frac{\partial}{\partial u^i}\widehat{G}.
		\]
	\end{lemma}

	\begin{proof}
		Отметим, что матрица в левой части точно нулевая всюду, кроме главного минора $2 \times 2$. Действительно, для правой нижней клетки это очевидно, а для остальных легко проверить. Проверим, например, для нижней центральной клетки:
		\[
			\begin{pmatrix}
				-b_{ik}g^{k1} & -b_{ik}g^{k2} & 0
			\end{pmatrix}
			\begin{pmatrix}
				g_{12}\\
				g_{22}\\
				0
			\end{pmatrix} +
			\begin{pmatrix}
				0 & 0 & 1
			\end{pmatrix}
			\begin{pmatrix}
				\Gamma_{11}^2\\
				\Gamma_{12}^2\\
				b_{i2}
			\end{pmatrix} = -b_{ik}g^{ks}g_{s2} + b_{i2} = -b_{i2} + b_{i2} = 0.
		\]
		
		Таким образом, вне главного минора $2 \times 2$ матрицы в левой и правой частях данного равенства обе нулевые. А внутри него у матрицы в левой части мы получаем правые части формул \eqref{eq:AlmostCristoffelIdentity}, что также совпадает с тем, что мы хотели получить.
	\end{proof}

	Итак, мы поняли, что матрицы $\widehat{G}$ и $\widetilde{G}$ удовлетворяют одним и тем же дифференциальным уравнениям. Мы также знаем, что в начальный момент эти матрицы совпадают: $\widehat{G}|_{(0, 0)} \hm= \widetilde{G}|_{(0, 0)}$. В силу дифференциальных уравнений, наши матрицы однозначно восстанавливаются по начальному условию, поэтому на самом деле они совпадают всюду.

	Таким образом, $\langle\vec{v}_i, \vec{v}_j\rangle = g_{ij}$ и $\langle\vec{v}_k, \vec{n}\rangle = 0$, поэтому наши $(g_{ij})$ действительно являются элементами матрицы первой квадратичной формы нашей поверхности, а вектор $\vec{n}$ --- вектором нормали. Теперь
	\[
		\left\langle\frac{\partial\vec{v}_i}{\partial u^j}, \vec{n}\right\rangle = \langle\Gamma_{ij}^k\vec{v_k} + b_{ij}\vec{n}, \vec{n}\rangle = b_{ij},
	\]
	так как $\vec{v}_k \perp \vec{n}$.
\end{proof}

\subsection{Уравнения Гаусса "---Кодацци}

На первый взгляд, система \eqref{eq:Jointness} содержит девять уравнений. Распишем их подробно, чтобы выяснить их истинное число и конкретный вид. Обозначим через $\widehat{G}$ матрицу Грама векторов $(\vec{r}_1, \vec{r}_2, \vec{n})$:
\[
	\widehat{G} \vcentcolon =
	\begin{pmatrix}
		g_{11} & g_{12} & 0\\
		g_{12} & g_{22} & 0\\
		0 & 0 & 1
	\end{pmatrix}.
\]

Ясно, что матрица $\widehat{G}$ невырожденна (её определитель равен определителю матрицы $\G$ первой квадратичной формы), а потому, домножив матрицу в левой части \eqref{eq:Jointness} на $\widehat{G}$, получим равносильную систему уравнений.

\begin{lemma}
	Матрица $\ds\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}$ кососимметрична.
\end{lemma}

\begin{proof}
	Обозначим эту матрицу через $S$. Применяя лемму \ref{lemma:Gui}, напишем
	\begin{multline*}
		S = \frac{\partial(\widehat{G}A_1)}{\partial u^2} - \frac{\partial \widehat{G}}{\partial u^2}A_1 - \frac{\partial(\widehat{G}A_2)}{\partial u^1} + \frac{\partial \widehat{G}}{\partial u^1}A_2 - \widehat{G}A_1A_2 + \widehat{G}A_2A_1 =\\ = \frac{\partial(\widehat{G}A_1)}{\partial u^2} - A_2^t\widehat{G}A_1 - \cancel{\widehat{G}A_2A_1} - \frac{\partial(\widehat{G}A_2)}{\partial u^1} + A_1^t\widehat{G}A_2 + \bcancel{\widehat{G}A_1A_2} - \bcancel{\widehat{G}A_1A_2} + \cancel{\widehat{G}A_2A_1} =\\ = \frac{\partial(\widehat{G}A_1)}{\partial u^2} - \frac{\partial(\widehat{G}A_2)}{\partial u^1} + {\underbrace{A_1^t\widehat{G}A_2 - A_2^t\widehat{G}A_1}_{\text{кососимметрична}}}.
	\end{multline*}
	Далее пишем
	\[
		S + S^t = \frac{\partial(\widehat{G}A_1 + A_1^t\widehat{G})}{\partial u^2} - \frac{\partial(\widehat{G}A_2 + A_2^t\widehat{G})}{\partial u^1} = \cancel{\frac{\partial^2\widehat{G}}{\partial u^1u^2}} - \cancel{\frac{\partial^2\widehat{G}}{\partial u^1u^2}} = 0.
	\]
	Таким образом, матрица $S$ кососимметрична.
\end{proof}

Итак, мы свели систему уравнений \eqref{eq:Jointness} на матрицу $3 \times 3$ к равносильной системе с кососимметричной матрицей. А у такой системы может быть не более трёх независимых уравнений. Будем изучать их по отдельности.

\begin{definition}
	Уравнение
	\[
		\br{\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}}_{12} = 0
	\]
	называется \textit{уравнением Гаусса}.
\end{definition}

\noindent%
Подставив матрицы $\widehat{G}$ и $A_i$, получаем развёрнутый вид уравнения Гаусса:
\begin{equation} \label{eq:Gauss}
	g_{1k}\br{\frac{\partial\Gamma^k_{22}}{\partial u^1} - \frac{\partial\Gamma_{21}^k}{\partial u^2} + \Gamma_{k1}^s\Gamma^k_{22} - \Gamma_{s2}^k\Gamma_{21}^s} - b_{12}b_{22} + b_{12}^2 = 0.
\end{equation}

Замечательно в этом уравнении то, что из него можно выразить определитель матрицы второй квадратичной формы через символы Кристоффеля, которые, в свою очередь, определяются только метрикой. Отсюда можем сделать следующие выводы.

\begin{theorem}[Гаусс]
	Гауссова кривизна однозначно определяется метрикой. Более точно, выполнена следующая формула:
	\[
		K = \frac{1}{g_{11}g_{22} - g_{12}^2}g_{1k}\br{\frac{\partial\Gamma^k_{22}}{\partial u^1} - \frac{\partial\Gamma_{21}^k}{\partial u^2} + \Gamma_{k1}^s\Gamma^k_{22} - \Gamma_{s2}^k\Gamma_{21}^s}.
	\]
\end{theorem}

\begin{corollary}
	Если $\vec{\varphi}\colon \M \to \mathcal{N}$ --- изометрия поверхностей, то для всех точек $\vec{x} \in \M$ гауссова кривизна поверхности $\mathcal{N}$ в точке $\vec{\varphi}(\vec{x})$ совпадает с гауссовой кривизной поверхности $\M$ в точке $\vec{x}$.
\end{corollary}

Обратное, вообще говоря, неверно --- существуют не локально изометричные поверхности с одинаковыми гауссовыми кривизнами. % TODO: привести пример!

\begin{problem}
	Две поверхности с равными \underline{постоянными} гауссовыми кривизнами локально изометричны.
\end{problem}

Вернёмся к уравнениям совместности. Мы рассмотрели одно уравнение из трёх независимых, осталось ещё два.

\begin{definition}
	Уравнения
	\[
		\br{\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}}_{31} = 0,\quad
		\br{\widehat{G}\br{\frac{\partial A_1}{\partial u^2} - \frac{\partial A_2}{\partial u^1} - A_1A_2 + A_2A_1}}_{32} = 0
	\]
	называются \textit{уравнениями Кодацци}.
\end{definition}

\noindent
При выполнении нужных подстановок уравнения Кодацци обретают вид
\begin{equation} \label{eq:Codazzi}
	\frac{\partial b_{12}}{\partial u^1} - \frac{\partial b_{11}}{\partial u^2} + b_{s1}\Gamma_{12}^s - b_{s2}\Gamma_{11}^s = 0,\quad
	\frac{\partial b_{22}}{\partial u^1} - \frac{\partial b_{21}}{\partial u^2} + b_{s1}\Gamma_{22}^s - b_{s2}\Gamma_{21}^s = 0.
\end{equation}

Вместе уравнения \eqref{eq:Gauss} и \eqref{eq:Codazzi} называются \textit{уравнениями Гаусса "---Кодацци} и выражают совместность деривационных уравнений Гаусса "---Вайнгартена.

% TODO: векторные поля, K = -1, теорема Бонне, ковариантное дифференцирование

\subsection{Векторные поля, скобка Ли}

\begin{definition}
	\textit{Векторным полем} на поверхности $\M$ называется отображение, которое каждой точке $\vec{x} \in \M$ ставит в соответствие вектор $\vec{v}(\vec{x})$ из касательной плоскости $\T_{\vec{x}}\M$. Векторное поле $\vec{v}$ называется \textit{гладким}, если в локальной параметризации коэффициенты $V^1$, $V^2$ разложения
	$\vec{v} = V^i\vec{r}_i$ вектора $\vec{v}$ по базису $\vec{r}_1$, $\vec{r}_2$ являются гладкими функциями.
\end{definition}

С каждой локальной системой координат связаны два базисных векторных поля, определённых в соответствующей области на поверхности --- это $\vec{r}_1$ и $\vec{r}_2$. Их координаты по отношению к этой локальной системе постоянны: $(1, 0)$ и $(0, 1)$ соответственно. Зададим следующий вопрос: когда данная пара векторных полей $\vec{v}$, $\vec{w}$ может быть парой базисных векторных полей для некоторой локальной системы координат?

Разумеется, для начала нужно потребовать, чтобы $\vec{v}$ и $\vec{w}$ были линейно независимы в каждой точке. Пусть это так в некоторой точке $\vec{x}_0$. Тогда они линейно независимы и в некоторой окрестности $U$ точки $\vec{x}_0$. Пусть $u^1$, $u^2$ --- некоторая локальная система координат в этой окрестности. Мы хотим выяснить, существует ли другая система координат $\widetilde{u}^1$, $\widetilde{u}^2$, для которой всюду в $U$ будет выполнено
\begin{equation} \label{eq:BasisVectorField}
	\vec{r}_{\widetilde{1}} = \vec{v},\quad\vec{r}_{\widetilde{2}} = \vec{w}.
\end{equation}
Найти такую систему координат $\widetilde{u}^1$, $\widetilde{u}^2$ означает найти функции перехода от неё к $u^1$, $u^2$ (или наоборот, что эквивалентно). Равенства \eqref{eq:BasisVectorField} равносильны следующим:
\[
	\frac{\partial u^i}{\partial \widetilde{u}^1}\vec{r}_i = V^i\vec{r}_i,\quad
	\frac{\partial u^i}{\partial \widetilde{u}^2}\vec{r}_i = W^i\vec{r}_i,
\]
то есть следующей системе из двух дифференциальных уравнений:
\[
	\begin{cases}
		\frac{\partial u^i}{\partial\widetilde{u}^1}\vec{r}_i = V^i(u^1, u^2),\\
		\frac{\partial u^i}{\partial\widetilde{u}^2}\vec{r}_i = W^i(u^1, u^2).
	\end{cases}
\]
Выписываем для неё условие совместности \eqref{eq:Darboux}:
\[
	\frac{\partial V^i}{\partial u^j}W^j = \frac{\partial W^i}{\partial u^j}V^j.
\]

\begin{definition}
	Для двух векторных полей $\vec{v}$, $\vec{w}$ их \textit{коммутатором} (\textit{скобкой Ли}) называется векторное поле
	\[
		[\vec{v}, \vec{w}] = \br{V^j\frac{\partial W^i}{\partial u^j} - W^j\frac{\partial V^i}{\partial u^j}}\vec{r}_i.
	\]
	Если $[\vec{v}, \vec{w}] \equiv \vec{0}$, то говорят, что поля $\vec{v}$ и $\vec{w}$ \textit{коммутируют}.
\end{definition}

% TODO: написать про геометрический смысл скобки Ли

\begin{proposition}
	Определение скобки Ли корректно, то есть не зависит от выбора системы координат.
\end{proposition}

\begin{proof}
	Рассмотрим $\vec{v}$ и $\vec{w}$ как отображения $\M \to \R^3$. По определению дифференциала, имеем для этих отображений:
	\[
		d\vec{v}(\vec{w}) = \frac{\partial(V^i\vec{r}_i)}{\partial u^j}W^j = \br{\frac{\partial V^i}{\partial u^j}\vec{r}_i + V^i\vec{r}_{ij}}W^j.
	\]
	Аналогично,
	\[
		d\vec{w}(\vec{v}) = \br{\frac{\partial W^i}{\partial u^j}\vec{r}_i + W^i\vec{r}_{ij}}V^j.
	\]
	Отметим, что второе слагаемое в обоих случаях одно и то же. Отсюда,
	\[
		d\vec{w}(\vec{v}) - d\vec{v}(\vec{w}) = \br{V^j\frac{\partial W^i}{\partial u^j} - W^j\frac{\partial V^i}{\partial u^j}}\vec{r}_i = [\vec{v}, \vec{w}].
	\]

	Таким образом, мы выразили скобку Ли $[\vec{v}, \vec{w}]$ через инвариантные величины $d\vec{w}(\vec{v})$ и $d\vec{v}(\vec{w})$. Отметим, что каждая из этих двух величин не задаёт, вообще говоря, касательного поля к поверхности.
\end{proof}

Используя введённое понятие коммутатора векторных полей, приведённое выше рассуждение резюмируется следующим образом.

\begin{theorem}
	Два векторных поля $\vec{v}$ и $\vec{w}$ являются базисными векторными полями для некоторой локальной системы координат тогда и только тогда, когда они линейно независимы и коммутируют.
\end{theorem}

\begin{problem}
	Доказать, что выполнено \textit{тождество Якоби}:
	\[
		\big[[\vec{v}_1, \vec{v}_2], \vec{v}_3\big] +
		\big[[\vec{v}_2, \vec{v}_3], \vec{v}_1\big] +
		\big[[\vec{v}_3, \vec{v}_1], \vec{v}_2\big] \equiv \vec{0}
	\]
	для любых трёх векторных полей $\vec{v}_1$, $\vec{v}_2$, $\vec{v}_3$.
\end{problem}

%\subsection{Поверхности постоянной отрицательной кривизны}
%
%Уравнения Кодацци \eqref{eq:Codazzi} --- это, вообще говоря, сложные уравнения в частных производных первого порядка. Но есть специальный случай, в котором их удаётся решить, это поверхности с постоянной отрицательной гауссовой кривизной. Отметим, что при гомотетиях гауссова кривизна поверхности умножается всюду на одно и то же положительное число, так что достаточно рассмотреть случай $K \equiv -1$.
%
%\begin{definition}
%	Касательный вектор $\vec{\xi} \in \T_{\vec{x}}\M$ называется \textit{асимптотическим}, если $\II|_{\vec{x}}(\vec{\xi}) = 0$. Кривая называется \textit{асимптотической линией}, если её вектор скорости в каждой точки асимптотический.
%\end{definition}


