\subsection*{Обозначения}

\begin{center}
\begin{minipage}{.9\textwidth}
	$\R$ --- поле (топологическое пространство) вещественных чисел;

	$\vec{x} = (x^1, \ldots, x^n)$ --- вектор (точка) из $\R^n$;
	
	$(\vec{e}_1, \ldots, \vec{e}_n)$ --- стандартный базис в $\R^n$;

	$\span(\vec{v}_1, \ldots, \vec{v}_n)$ --- линейная оболочка векторов $\vec{v}_1, \ldots, \vec{v}_n$;

	$S_{\Or}(\vec{u}, \vec{v})$ --- ориентированная площадь параллелограмма, натянутого на векторы $\vec{u}$ и $\vec{v}$, $\Vol_{\Or}(\vec{v}_1, \ldots, \vec{v}_n)$ --- ориентированный объём $n$-мерного параллелепипеда, натянутого на векторы $\vec{v}_1,\,\ldots,\,\vec{v}_n$;

	$I$ --- связное подмножество $\R$;

	$\Int U$ --- внутренность подмножества $U \subset \R^n$;

	$\langle\vec{x}, \vec{y}\rangle$ --- евклидово скалярное произведение векторов $\vec{x},\,\vec{y} \in \R^n$;

	$\langle\vec{x}, \vec{y}\rangle_\G$ --- скалярное произведение векторов $\vec{x},\,\vec{y} \in \R^n$, задаваемое положительно определённой симметричной матрицей $\G$ (то есть $\langle\vec{x}, \vec{y}\rangle_\G = \vec{x}^t\G\vec{y}$);

	$\vec{x} \times \vec{y}$ --- векторное произведение векторов $\vec{x},\,\vec{y} \in \R^3$;

	$\rho(\vec{x}, \vec{y})$ --- расстояние между точками $\vec{x}$ и $\vec{y}$ из $\R^n$;

	$\vec{r}(t) = (x^1(t), \ldots, x^n(t))$ --- радиус-вектор точки $\vec{x} \in \R^n$;

	$\dot{\vec{r}}(t),\,\ddot{\vec{r}}(t),\,\ldots$ --- векторы скорости, ускорения и т.\,д. точки $\vec{x} \in \R^n$.

	\medskip
	\textbf{Нотация Эйнштейна}. {\small По дважды повторяющимся индексам, один из которых верхний, а другой нижний, подразумевается суммирование в пределах, устанавливаемых из контекста, а сам такой индекс называется \textit{слепым}. Верхний индекс переменной, появляющейся в знаменателе, считается для выражения нижним, и наоборот.}
\end{minipage}
\end{center}

\section{Предварительные сведения и напоминания}

\epigraph{Сначала вы подумаете, что я сумасшедший, а потом вам понравится, и вы сами будете делать так же.}{А.\,В. Пенской}

\subsection*{Математический анализ}

Отображение $\vec{f}\colon \R^n \to \R^m$ называется \textit{дифференцируемым в точке} $\vec{x}_0$, если существует линейное отображение $\mathcal{L}_{\vec{x}_0}$, для которого выполнено
\[
	\vec{f}(\vec{x}) = \vec{f}(\vec{x}_0) + \mathcal{L}_{\vec{x}_0}(\vec{x} - \vec{x}_0) + \o(\norm{\vec{x} - \vec{x}_0})\text{ при $\vec{x} \to \vec{x}_0$}.
\]

При этом отображение $\vec{f}$ не обязано быть определено всюду. Нам будет достаточно, чтобы в область определения отображения $\vec{f}$ входило замыкание некоторой выпуклой открытой области, содержащее точку $\vec{x}_0$. Однозначно определённое линейное отображение $\mathcal{L}_{\vec{x}_0} = \vcentcolon \left.d\vec{f}\right|_{\vec{x_0}}$ называют \textit{дифференциалом} отображения $\vec{f}$ в точке $\vec{x}$.

Матрица $J_{\vec{f}}(\vec{x}_0)$ линейного отображения $\left.d\vec{f}\right|_{\vec{x}_0}$ называется \textit{матрицей Якоби} отображения $\vec{f}$ в точке $\vec{x}_0$ и состоит из \textit{частных производных}:

\[
	J_{\vec{f}}(\vec{x}_0) =
	\begin{pmatrix}
		\ds\left.\frac{\partial f^1}{\partial x^1}\right|_{\vec{x}_0} & \ds\ldots & \ds\left.\frac{\partial f^1}{\partial x^n}\right|_{\vec{x}_0} \\
		\ds\vdots & \ds\ddots & \ds\vdots \\
		\ds\left.\frac{\partial f^m}{\partial x^1}\right|_{\vec{x}_0} & \ds\ldots & \ds\left.\frac{\partial f^m}{\partial x^n}\right|_{\vec{x}_0} \\
	\end{pmatrix} =
	\begin{pmatrix}
		\left.\nabla f^1\right|_{\vec{x}_0} \\
		\vdots\\
		\left.\nabla f^m\right|_{\vec{x}_0} \\
	\end{pmatrix}.
\]
В случае, когда эта матрица квадратная, её определитель называют \textit{якобиантом}.

Дифференцируемое отображение $\vec{f}$ определяет новое отображение $\partial \vec{f} / \partial \vec{x}\colon \R^n \to \R^m$. Если последнее также дифференцируемо, то $\vec{f}$ называется \textit{дважды дифференцируемым}, и далее индуктивно: если $\partial\vec{f} / \partial\vec{x}$ дифференцируемо $k$ раз, то $\vec{f}$ дифференцируемо $k + 1$ раз. Если отображение $\vec{f}$ дифференцируемо $k$ раз и при $k$-кратном дифференцировании получается непрерывное отображение, то говорят, что $\vec{f}$ \textit{$k$ раз непрерывно дифференцируемо} или является \textit{отображением класса $C^k$}. В дальнейшем под \textit{гладким отображением} мы будем подразумевать отображение класса $C^k$ для достаточно большого $k$.

\begin{theorem}[О производной сложной функции]
	Если отображения $\vec{f}\colon \R^n \to \R^m$ и $\vec{g}\colon \R^m \to \R^k$ дифференцируемы, то дифференцируема и композиция $\vec{g} \circ \vec{f}$, причём
	\[
		\left.d(\vec{g} \circ \vec{f})\right|_{\vec{x}_0} = \left.d\vec{g}\right|_{\vec{f}(\vec{x_0})} \circ \left.d\vec{f}\right|_{\vec{x}_0}.
	\]
\end{theorem}

\begin{theorem}[Об обратном отображении]
	Гладкое отображение $\vec{f}\colon \R^n \to \R^n$, матрица Якоби которого невырожденна в точке $\vec{x}_0$, локально обратимо в некоторой окрестности точки $\vec{x}_0$, причём обратное отображение также гладкое.
\end{theorem}

\begin{theorem}[О неявном отображении]
	Пусть $\vec{f}\colon \R^n \to \R^m$, $m \leqslant n$, --- гладкое отображение, матрица Якоби которого в точке $\vec{x}_0$ имеет ранг $m$. Тогда множество решений уравнения $\vec{f}(\vec{x}) = \vec{f}(\vec{x}_0)$ в окрестности точки $\vec{x}_0$ выглядит как график гладкого отображения, выражающего некоторые $m$ координат через оставшиеся $n - m$, причём эти $m$ координат можно выбрать те, которым соответствуют линейно независимые столбцы в матрице Якоби.
\end{theorem}

\subsection*{Аналитическая геометрия и линейная алгебра}

Пусть в $\R^n$ есть некоторая поверхность, задаваемая уравнением $F(x^1, \ldots, x^n) = 0$, а по ней движется точка, радиус-вектор которой есть $\vec{x} = \vec{r}(t)$. Тогда можем продифференцировать тождество $F(r^1(t), \ldots, r^n(t)) = 0$ в каждой точке, получив по теореме о сложной функции
\[
	\frac{\partial F}{\partial r^1} \cdot \frac{d r^1}{dt} + \ldots + \frac{\partial F}{\partial r^n} \cdot \frac{d r^n}{dt} = 0
\]
или, что то же, $\langle \nabla F, \dot{\vec{r}} \rangle = 0$.

Из правила Лейбинца сразу следует формула дифференцирования скалярного произведения:
\[
	\frac{d}{dt}\langle \vec{a}(t), \vec{b}(t) \rangle = \langle \dot{\vec{a}}(t), \vec{b}(t) \rangle + \langle \vec{a}(t), \dot{\vec{b}}(t) \rangle.
\]

Важный частный случай: если $\vec{a}(t) \perp \vec{b}(t)$ для всех значений параметра $t$, то $\langle\vec{a}(t), \dot{\vec{b}}(t)\rangle \hm= -\langle\dot{\vec{a}}(t), \vec{b}(t)\rangle$. Аналогичная формула верна и для векторного произведения:
\[
	\frac{d}{dt}(\vec{a}(t) \times \vec{b}(t)) = (\dot{\vec{a}}(t) \times \vec{b}(t)) + (\vec{a}(t) \times \dot{\vec{b}}(t)).
\]

Пусть $\vec{r}\colon \R \to \R^n$. Тогда $\abs{\vec{r}} = \const$ тогда и только тогда, когда $\langle \vec{r}, \dot{\vec{r}} \rangle = 0$. Доказательство простое --- надо продифференцировать тождество $\langle \vec{r}(t), \vec{r}(t) \rangle = \const$. Можно доказать и по-другому --- вектор постоянной длины $\abs{\vec{r}} = \const$ лежит на сфере, уравнение которой $F(x_1, \ldots, x_n) = x_1^2 + \ldots + x_n^2 = \const$. При этом
\[\begin{tikzcd}
	{0} & {\langle\nabla{F}, \dot{\vec{r}}\rangle} & {\langle 2\vec{r}, \dot{\vec{r}}\rangle = 2\langle\vec{r}, \dot{\vec{r}}\rangle}.
	\arrow[equals, from=1-2, to=1-1]
	\arrow[equals, from=1-2, to=1-3]
\end{tikzcd}\]

Проекция вектора $\vec{u}$ на вектор $\vec{v}$ вычисляется по формуле
\[
	\proj_{\vec{v}}\vec{u} = \frac{\langle\vec{u}, \vec{v}\rangle}{\langle\vec{v}, \vec{v}\rangle} \cdot \vec{v}.
\]

\textit{Ортогонализацией Грамма "---Шмидта} называется процедура перехода от линейно независимого набора векторов $\vec{a}_1, \ldots, \vec{a}_k$ к набору попарно ортогональных векторов $\vec{b}_1, \ldots, \vec{b}_k$ такому, что $\span(\vec{a}_1, \ldots, \vec{a}_k) = \span(\vec{b}_1, \ldots, \vec{b}_k)$. Этот процесс описывается индуктивными формулами $\vec{b}_1 = \vec{a}_1$, $\vec{b}_{i + 1} = \vec{a}_{i + 1} - \proj_{\vec{b}_1}\vec{a}_{i + 1} - \ldots - \proj_{\vec{b}_i}\vec{a}_{i + 1}$.

\begin{theorem}[Критерий Сильвестра]
	Квадратичная форма с матрицей $\mathcal{B}$
	\begin{enumerate}[nolistsep, label=(\arabic*)]
		\item положительно определена тогда и только тогда, когда определители всех главных миноров матрицы $\mathcal{B}$ положительны;
		\item отрицательно определена тогда и только тогда, когда определители всех главных миноров матрицы $\mathcal{B}$ образуют знакочередующуюся последовательность, первый член которой отрицательный.
	\end{enumerate}
\end{theorem}

\medskip
\hrule
\medskip

Фразу, упомянутую в эпиграфе к данному разделу, А.\,В. Пенской произнёс на первой лекции своего курса по дифференциальной геометрии в НМУ 2025 года.

Рассмотрим евклидову плоскость\footnotemark{} $\mathbb{E}^2$ и фиксированную точку $O$ на ней. Пусть на этой плоскости задана функция $f(\vec{x}) = \big|\overrightarrow{O\vec{x}}\big|$ (измеряем евклидово расстояние до заданной точки). Мы можем ввести евклидовы координаты в этой плоскости, в них наша функция записывается как $f(x, y) = \sqrt{x^2 + y^2}$. А можем ввести полярные, и тогда функция записывается как $f(\rho, \varphi) = \rho$. Наблюдаем некоторое противоречие --- одна и та же функция $f$ от двух аргументов записывается двумя (очевидно, различными) способами, то есть формально нельзя написать $f(x, y) = f(\rho, \varphi)$. Но мы так пишем, и мы на самом деле хотим так писать. Так в чём же дело?

\footnotetext{Везде в тексте, кроме этого комментария, евклидово пространство размерности $n$ отождествляется с $\R^n$. Здесь важно сохранить обозначения Алексея Викторовича.} 

Корень этого мнимого противоречия заключается в том, как мы думаем о функциях в алгебре и анализе. Мы привыкли к тому, что функция --- это <<алгоритм вычисления>>. С этой точки зрения $f(\rho, \varphi)$ должно быть равно $\sqrt{\rho^2 + \varphi^2}$, но ведь ясно, что мы имеем в виду не это. А на самом деле происходит следующее.

\shorthandoff{"}%
\[\begin{tikzcd}
	{\underset{\mathclap{x,\,y}}{\mathbb{R}}^2} \\
	& {\mathbb{E}^2} && {\mathbb{R}} \\
	{\underset{\mathclap{\rho,\,\varphi}}{\mathbb{R}}^2}
	\arrow["\Phi", from=1-1, to=2-2]
	\arrow["f", from=2-2, to=2-4]
	\arrow["\Psi"', from=3-1, to=2-2]
\end{tikzcd}\]
\shorthandon{"}%

Имеет место такая коммутативная диаграмма, где отображения $\Phi$ и $\Psi$ задают выбор системы координат. Запись $f(x, y) = \sqrt{x^2 + y^2}$ формально некорректна, ведь на самом деле таким образом задаётся не функция $f$, а композиция $(f \circ \Phi)(x, y) = \sqrt{x^2 + y^2}$. Так же можно написать и в полярных координатах: $(f \circ \Psi)(\rho, \varphi) = \rho$. И то, что мы имеем в виду под записью $f(x, y) = f(\rho, \varphi)$, формально записывается как
\[
	f \circ \Phi = f \circ \Psi.
\]

Сама функция $f$ задана абстрактно, в её определении не фигурировали координаты, поэтому писать $f(x, y) = \ldots$ (или $f(\rho, \varphi) = \ldots$) формально нельзя. Но мы, конечно же, будем, потому что для нас первично абстрактное задание функции, а не система координат (или параметризация), в которой мы хотим её записать.

Теперь можем написать ещё более <<удивительную>> формулу:
\[
	f(\rho, \varphi) = f\big(x(\rho, \varphi),\,y(\rho, \varphi)\big).
\]

Если уж мы согласились с равенством $f(\rho, \varphi) = f(x, y)$, то мы обязаны согласиться и с этим равенством, ведь от первого ко второму можно перейти, рассматривая $x$ и $y$ как функции $x(\rho, \varphi) = \rho\cos\varphi$, $y(\rho, \varphi) = \rho\sin\varphi$. И мы действительно можем с ним согласиться, ведь формально это равенство можно записать как
\[
	f \circ \Psi = (f \circ \Phi) \circ (\Phi^{-1} \circ \Psi).
\]
Эта формула является тождеством в силу ассоциативности композиции.

%Напомним определение тензора. Пусть $V$ --- линейное пространство над полем $\Bbbk$.
%
%\begin{definition}
%	\textit{Полилинейной функцией типа $(p, q)$} называется функция
%	\[
%		\T\colon \underbrace{V^\ast \times \ldots \times V^\ast}_p \times \underbrace{V \times \ldots \times V}_q \to \Bbbk
%	\]
%	от $p$ ковекторных и $q$ векторных аргументов, которая линейна по каждому аргументу.
%\end{definition}
%
%Зафиксируем базис $\vec{e}_1, \ldots, \vec{e}_n$ в пространстве $V$. В пространстве $V^\ast$ имеется двойственный базис $\eps^1, \ldots, \eps^n$, где $\eps^i(\vec{e}_j) = \delta^i_j$. Тогда любая полилинейная функция задаётся своими значениями на базисных векторах и ковекторах:
%\begin{multline} \label{eq:PolylinearBasis}
%	\T(\xi^1, \ldots, \xi^p, \vec{v}_1, \ldots, \vec{v}_q) = \T(\xi^1_{i_1}\eps^{i_1}, \ldots, \xi^p_{i_p}\eps^{i_p}, v^{j_1}_1\vec{e}_{j_1}, \ldots, v^{j_q}_q\vec{e}_{j_q}) =\\ = \xi^1_{i_1}\ldots\xi^p_{i_p}v^{j_1}_1\ldots v_q^{j_q}\T(\eps^{i_1}, \ldots, \eps^{i_p}, \vec{e}_{j_1}, \ldots, \vec{e}_{j_q}).
%\end{multline}
%
%Сопоставим полилинейной функции $\T$ типа $(p, q)$ и базису $\vec{e}_1, \ldots, \vec{e}_n$ набор из $n^{p + q}$ чисел $T = \{T^{i_1, \ldots, i_p}_{j_1, \ldots, j_q}\}$, где
%\[
%	T^{i_1, \ldots, i_p}_{j_1, \ldots, j_q} \vcentcolon = \T(\eps^{i_1}, \ldots, \eps^{i_p}, \vec{e}_{j_1}, \ldots, \vec{e}_{j_q}).
%\]
%
%Посмотрим, как преобразуется этот набор при заменах базиса. Пусть $C = (c^i_{i^\prime})$ --- матрица перехода от базиса $\vec{e}_1, \ldots, \vec{e}_n$ к базису $\vec{e}_{1^\prime}, \ldots, \vec{e}_{n^\prime}$. Тогда имеем $\vec{e}_{j^\prime} = c^j_{j^\prime}\vec{e}_j$, $\eps^{i^\prime} = c^{i^\prime}_i\eps^i$~и
%\begin{multline} \label{eq:TensorLaw}
%	T^{i_1^\prime, \ldots, i_p^\prime}_{j_1^\prime, \ldots, j_q^\prime} = \T(\eps^{i_1^\prime}, \ldots, \eps^{i_p^\prime}, \vec{e}_{j_1^\prime}, \ldots, \vec{e}_{j_q^\prime}) = \T(c^{i_1^\prime}_{i_1}\eps^{i_1}, \ldots, c^{i_p^\prime}_{i_p}\eps^{i_p}, c^{j_1}_{j_1^\prime}\vec{e}_{j_1}, \ldots, c^{j_q}_{j_q^\prime}\vec{e}_{j_q}) =\\ = c^{i_1^\prime}_{i_1}\ldots c^{i_p^\prime}_{i_p} c^{j_1}_{j_1^\prime}\ldots c^{j_q}_{j_q^\prime}\T(\eps^{i_1}, \ldots, \eps^{i_p}, \vec{e}_{j_1}, \ldots, \vec{e}_{j_q}) = c^{i_1^\prime}_{i_1}\ldots c^{i_p^\prime}_{i_p} c^{j_1}_{j_1^\prime}\ldots c^{j_q}_{j_q^\prime}T^{i_1, \ldots, i_p}_{j_1, \ldots, j_q}.
%\end{multline}
%
%\begin{definition}
%	\textit{Тензором} типа $(p, q)$ называется соответствие
%	\[
%		\text{базисы в $V$} \leftrightarrow \text{наборы из $n^{p + q}$ чисел $T = \{T^{i_1, \ldots, i_p}_{j_1, \ldots, j_q}\}$},
%	\]
%	при котором наборы $T = \{T^{i_1, \ldots, i_p}_{j_1, \ldots, j_q}\}$ и $T^\prime = T^{i_1^\prime, \ldots, i_p^\prime}_{j_1^\prime, \ldots, j_q^\prime}$, соответствующие различным базисам $\vec{e}_1, \ldots, \vec{e}_n$ и $\vec{e}_{1^\prime}, \ldots, \vec{e}_{n^\prime}$, связаны соотношением \[T^{i_1^\prime, \ldots, i_p^\prime}_{j_1^\prime, \ldots, j_q^\prime} = c^{i_1^\prime}_{i_1}\ldots c^{i_p^\prime}_{i_p} c^{j_1}_{j_1^\prime}\ldots c^{j_q}_{j_q^\prime}T^{i_1, \ldots, i_p}_{j_1, \ldots, j_q},\] которое называется \textit{тензорным законом преобразования}.
%\end{definition}
%
%Тензор определяет полилинейную функцию по формулы \eqref{eq:PolylinearBasis}, и наоборот --- полилинейная функция определяет тензор по формуле \eqref{eq:TensorLaw}.

