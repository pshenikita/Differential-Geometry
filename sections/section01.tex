\subsection*{Обозначения}

\begin{center}
\begin{minipage}{.9\textwidth}
	$\R$ --- поле (топологическое пространство) вещественных чисел;

	$\vec{x} = (x^1, \ldots, x^n)$ --- вектор (точка) из $\R^n$;
	
	$(\vec{e}_1, \ldots, \vec{e}_n)$ --- стандартный базис в $\R^n$;

	$\span(\vec{v}_1, \ldots, \vec{v}_n)$ --- линейная оболочка векторов $\vec{v}_1, \ldots, \vec{v}_n$;

	$S_{\Or}(\vec{u}, \vec{v})$ --- ориентированная площадь параллелограмма, натянутого на векторы $\vec{u}$ и $\vec{v}$, $\Vol_{\Or}(\vec{v}_1, \ldots, \vec{v}_n)$ --- ориентированный объём $n$-мерного параллелепипеда, натянутого на векторы $\vec{v}_1,\,\ldots,\,\vec{v}_n$;

	$I$ --- связное подмножество $\R$;

	$\Int U$ --- внутренность подмножества $U \subset \R^n$;

	$\langle\vec{x}, \vec{y}\rangle$ --- евклидово скалярное произведение векторов $\vec{x},\,\vec{y} \in \R^n$;

	$\langle\vec{x}, \vec{y}\rangle_\G$ --- скалярное произведение векторов $\vec{x},\,\vec{y} \in \R^n$, задаваемое положительно определённой симметричной матрицей $\G$ (то есть $\langle\vec{x}, \vec{y}\rangle_\G = \vec{x}^t\G\vec{y}$);

	$\vec{x} \times \vec{y}$ --- векторное произведение векторов $\vec{x},\,\vec{y} \in \R^3$;

	$\rho(\vec{x}, \vec{y})$ --- расстояние между точками $\vec{x}$ и $\vec{y}$ из $\R^n$;

	$\vec{r}(t) = (x^1(t), \ldots, x^n(t))$ --- радиус-вектор точки $\vec{x} \in \R^n$;

	$\dot{\vec{r}}(t),\,\ddot{\vec{r}}(t),\,\ldots$ --- векторы скорости, ускорения и т.\,д. точки $\vec{x} \in \R^n$.

	\medskip
	\textbf{Нотация Эйнштейна}. {\small По дважды повторяющимся индексам, один из которых верхний, а другой нижний, подразумевается суммирование в пределах, устанавливаемых из контекста, а сам такой индекс называется \textit{слепым}. Верхний индекс переменной, появляющейся в знаменателе, считается для выражения нижним, и наоборот.}
\end{minipage}
\end{center}

\section{Предварительные сведения и напоминания}

\epigraph{Сначала вы подумаете, что я сумасшедший, а потом вам понравится, и вы сами будете делать так же.}{А.\,В. Пенской}

\subsection{Математический анализ}

Отображение $\vec{f}\colon \R^n \to \R^m$ называется \textit{дифференцируемым в точке} $\vec{x}_0$, если существует линейное отображение $\mathcal{L}_{\vec{x}_0}$, для которого выполнено
\[
	\vec{f}(\vec{x}) = \vec{f}(\vec{x}_0) + \mathcal{L}_{\vec{x}_0}(\vec{x} - \vec{x}_0) + \o(\norm{\vec{x} - \vec{x}_0})\text{ при $\vec{x} \to \vec{x}_0$}.
\]

При этом отображение $\vec{f}$ не обязано быть определено всюду. Нам будет достаточно, чтобы в область определения отображения $\vec{f}$ входило замыкание некоторой выпуклой открытой области, содержащее точку $\vec{x}_0$. Однозначно определённое линейное отображение $\mathcal{L}_{\vec{x}_0} = \vcentcolon \left.d\vec{f}\right|_{\vec{x_0}}$ называют \textit{дифференциалом} отображения $\vec{f}$ в точке $\vec{x}$.

Матрица $J_{\vec{f}}(\vec{x}_0)$ линейного отображения $\left.d\vec{f}\right|_{\vec{x}_0}$ называется \textit{матрицей Якоби} отображения $\vec{f}$ в точке $\vec{x}_0$ и состоит из \textit{частных производных}:

\[
	J_{\vec{f}}(\vec{x}_0) =
	\begin{pmatrix}
		\ds\left.\frac{\partial f^1}{\partial x^1}\right|_{\vec{x}_0} & \ds\ldots & \ds\left.\frac{\partial f^1}{\partial x^n}\right|_{\vec{x}_0} \\
		\ds\vdots & \ds\ddots & \ds\vdots \\
		\ds\left.\frac{\partial f^m}{\partial x^1}\right|_{\vec{x}_0} & \ds\ldots & \ds\left.\frac{\partial f^m}{\partial x^n}\right|_{\vec{x}_0} \\
	\end{pmatrix} =
	\begin{pmatrix}
		\left.\nabla f^1\right|_{\vec{x}_0} \\
		\vdots\\
		\left.\nabla f^m\right|_{\vec{x}_0} \\
	\end{pmatrix}.
\]
В случае, когда эта матрица квадратная, её определитель называют \textit{якобиантом}.

Дифференцируемое отображение $\vec{f}$ определяет новое отображение $\partial \vec{f} / \partial \vec{x}\colon \R^n \to \R^m$. Если последнее также дифференцируемо, то $\vec{f}$ называется \textit{дважды дифференцируемым}, и далее индуктивно: если $\partial\vec{f} / \partial\vec{x}$ дифференцируемо $k$ раз, то $\vec{f}$ дифференцируемо $k + 1$ раз. Если отображение $\vec{f}$ дифференцируемо $k$ раз и при $k$-кратном дифференцировании получается непрерывное отображение, то говорят, что $\vec{f}$ \textit{$k$ раз непрерывно дифференцируемо} или является \textit{отображением класса $C^k$}. В дальнейшем под \textit{гладким отображением} мы будем подразумевать отображение класса $C^k$ для достаточно большого $k$.

\begin{theorem}[О производной сложной функции]
	Если отображения $\vec{f}\colon \R^n \to \R^m$ и $\vec{g}\colon \R^m \to \R^k$ дифференцируемы, то дифференцируема и композиция $\vec{g} \circ \vec{f}$, причём
	\[
		\left.d(\vec{g} \circ \vec{f})\right|_{\vec{x}_0} = \left.d\vec{g}\right|_{\vec{f}(\vec{x_0})} \circ \left.d\vec{f}\right|_{\vec{x}_0}.
	\]
\end{theorem}

\begin{theorem}[Об обратном отображении]
	Гладкое отображение $\vec{f}\colon \R^n \to \R^n$, матрица Якоби которого невырожденна в точке $\vec{x}_0$, локально обратимо в некоторой окрестности точки $\vec{x}_0$, причём обратное отображение также гладкое.
\end{theorem}

\begin{theorem}[О неявном отображении]
	Пусть $\vec{f}\colon \R^n \to \R^m$, $m \leqslant n$, --- гладкое отображение, матрица Якоби которого в точке $\vec{x}_0$ имеет ранг $m$. Тогда множество решений уравнения $\vec{f}(\vec{x}) = \vec{f}(\vec{x}_0)$ в окрестности точки $\vec{x}_0$ выглядит как график гладкого отображения, выражающего некоторые $m$ координат через оставшиеся $n - m$, причём эти $m$ координат можно выбрать те, которым соответствуют линейно независимые столбцы в матрице Якоби.
\end{theorem}

\subsection{Аналитическая геометрия и линейная алгебра}

Пусть в $\R^n$ есть некоторая поверхность, задаваемая уравнением $F(x^1, \ldots, x^n) = 0$, а по ней движется точка, радиус-вектор которой есть $\vec{x} = \vec{r}(t)$. Тогда можем продифференцировать тождество $F(r^1(t), \ldots, r^n(t)) = 0$ в каждой точке, получив по теореме о сложной функции
\[
	\frac{\partial F}{\partial r^1} \cdot \frac{d r^1}{dt} + \ldots + \frac{\partial F}{\partial r^n} \cdot \frac{d r^n}{dt} = 0
\]
или, что то же, $\langle \nabla F, \dot{\vec{r}} \rangle = 0$.

Из правила Лейбинца сразу следует формула дифференцирования скалярного произведения:
\[
	\frac{d}{dt}\langle \vec{a}(t), \vec{b}(t) \rangle = \langle \dot{\vec{a}}(t), \vec{b}(t) \rangle + \langle \vec{a}(t), \dot{\vec{b}}(t) \rangle.
\]

Важный частный случай: если $\vec{a}(t) \perp \vec{b}(t)$ для всех значений параметра $t$, то $\langle\vec{a}(t), \dot{\vec{b}}(t)\rangle \hm= -\langle\dot{\vec{a}}(t), \vec{b}(t)\rangle$. Аналогичная формула верна и для векторного произведения:
\[
	\frac{d}{dt}(\vec{a}(t) \times \vec{b}(t)) = (\dot{\vec{a}}(t) \times \vec{b}(t)) + (\vec{a}(t) \times \dot{\vec{b}}(t)).
\]

Пусть $\vec{r}\colon \R \to \R^n$. Тогда $\abs{\vec{r}} = \const$ тогда и только тогда, когда $\langle \vec{r}, \dot{\vec{r}} \rangle = 0$. Доказательство простое --- надо продифференцировать тождество $\langle \vec{r}(t), \vec{r}(t) \rangle = \const$. Можно доказать и по-другому --- вектор постоянной длины $\abs{\vec{r}} = \const$ лежит на сфере, уравнение которой $F(x_1, \ldots, x_n) = x_1^2 + \ldots + x_n^2 = \const$. При этом
\[\begin{tikzcd}
	{0} & {\langle\nabla{F}, \dot{\vec{r}}\rangle} & {\langle 2\vec{r}, \dot{\vec{r}}\rangle = 2\langle\vec{r}, \dot{\vec{r}}\rangle}.
	\arrow[equals, from=1-2, to=1-1]
	\arrow[equals, from=1-2, to=1-3]
\end{tikzcd}\]

Проекция вектора $\vec{u}$ на вектор $\vec{v}$ вычисляется по формуле
\[
	\proj_{\vec{v}}\vec{u} = \frac{\langle\vec{u}, \vec{v}\rangle}{\langle\vec{v}, \vec{v}\rangle} \cdot \vec{v}.
\]

Объём сведений из линейной алгебры, которые необходимы в курсе дифференциальной геометрии (и в других дисциплинах), начинает становиться слишком большим для маленького раздела напоминаний в этом файле, поэтому я решил вынести его в отдельный проект, с которым можно ознакомиться \href{https://github.com/pshenikita/Linal-Teormin}{по ссылке}.

\subsection{Про функции в геометрии}

Фразу, упомянутую в эпиграфе к данному разделу, А.\,В. Пенской произнёс на первой лекции своего курса по дифференциальной геометрии в 2025\,г.

Рассмотрим евклидову плоскость\footnotemark{} $\mathbb{E}^2$ и фиксированную точку $O$ на ней. Пусть на этой плоскости задана функция $f(\vec{x}) = \big|\overrightarrow{O\vec{x}}\big|$ (измеряем евклидово расстояние до заданной точки). Мы можем ввести евклидовы координаты в этой плоскости, в них наша функция записывается как $f(x, y) = \sqrt{x^2 + y^2}$. А можем ввести полярные, и тогда функция записывается как $f(\rho, \varphi) = \rho$. Наблюдаем некоторое противоречие --- одна и та же функция $f$ от двух аргументов записывается двумя (очевидно, различными) способами, то есть формально нельзя написать $f(x, y) = f(\rho, \varphi)$. Но мы так пишем, и мы на самом деле хотим так писать. Так в чём же дело?

\footnotetext{Везде в тексте, кроме этого комментария, евклидово пространство размерности $n$ отождествляется с $\R^n$. Здесь важно сохранить обозначения Алексея Викторовича.} 

Корень этого мнимого противоречия заключается в том, как мы думаем о функциях в алгебре и анализе. Мы привыкли к тому, что функция --- это <<алгоритм вычисления>>. С этой точки зрения $f(\rho, \varphi)$ должно быть равно $\sqrt{\rho^2 + \varphi^2}$, но ведь ясно, что мы имеем в виду не это. А на самом деле происходит следующее.

\shorthandoff{"}%
\[\begin{tikzcd}
	{\underset{\mathclap{x,\,y}}{\mathbb{R}}^2} \\
	& {\mathbb{E}^2} && {\mathbb{R}} \\
	{\underset{\mathclap{\rho,\,\varphi}}{\mathbb{R}}^2}
	\arrow["\Phi", from=1-1, to=2-2]
	\arrow["f", from=2-2, to=2-4]
	\arrow["\Psi"', from=3-1, to=2-2]
\end{tikzcd}\]
\shorthandon{"}%

Имеет место такая коммутативная диаграмма, где отображения $\Phi$ и $\Psi$ задают выбор системы координат. Запись $f(x, y) = \sqrt{x^2 + y^2}$ формально некорректна, ведь на самом деле таким образом задаётся не функция $f$, а композиция $(f \circ \Phi)(x, y) = \sqrt{x^2 + y^2}$. Так же можно написать и в полярных координатах: $(f \circ \Psi)(\rho, \varphi) = \rho$. И то, что мы имеем в виду под записью $f(x, y) = f(\rho, \varphi)$, формально записывается как
\[
	f \circ \Phi = f \circ \Psi.
\]

Сама функция $f$ задана абстрактно, в её определении не фигурировали координаты, поэтому писать $f(x, y) = \ldots$ (или $f(\rho, \varphi) = \ldots$) формально нельзя. Но мы, конечно же, будем, потому что для нас первично абстрактное задание функции, а не система координат (или параметризация), в которой мы хотим её записать.

Теперь можем написать ещё более <<удивительную>> формулу:
\[
	f(\rho, \varphi) = f\big(x(\rho, \varphi),\,y(\rho, \varphi)\big).
\]

Если уж мы согласились с равенством $f(\rho, \varphi) = f(x, y)$, то мы обязаны согласиться и с этим равенством, ведь от первого ко второму можно перейти, рассматривая $x$ и $y$ как функции $x(\rho, \varphi) = \rho\cos\varphi$, $y(\rho, \varphi) = \rho\sin\varphi$. И мы действительно можем с ним согласиться, ведь формально это равенство можно записать как
\[
	f \circ \Psi = (f \circ \Phi) \circ (\Phi^{-1} \circ \Psi).
\]

